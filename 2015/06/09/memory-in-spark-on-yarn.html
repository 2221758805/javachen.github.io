<!DOCTYPE html>
<html lang="zh-cn">
        <head>
      <meta charset="utf-8"/>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
      <title>Spark On YARN内存分配 - JavaChen Blog</title>
      <meta name="author" content="JavaChen"/>
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
      <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
      <link rel="canonical" href="http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html" />

      <link rel="stylesheet" href="/static/contrib/bootstrap/css/bootstrap.min.css" media="all" />
      <link rel="stylesheet" href="/static/css/style.css" media="all" />
      <link rel="stylesheet" href="/static/css/pygments.css" media="all" />
      <link rel="stylesheet" href="/static/contrib/font-awesome/css/font-awesome.min.css" media="all" />
      <link rel="stylesheet" type="text/css" href="/static/contrib/showup/showup.css" />
        
        <!-- fav and touch icons  -->
        <!-- Update these with your own images
        <link rel="shortcut icon" href="images/favicon.ico">
        <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
        <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
        -->

      <meta name="renderer" content="webkit|ie-stand">
      <meta name="baidu-site-verification" content="3HAhaWRiyR" />
      <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
      <meta name="sogou_site_verification" content="ofwXWFdthV"/>
      <meta property="wb:webmaster" content="b6081b2b8ab84c60" />
    </head>

    <body>
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">JavaChen Blog</a>
        </div>
        <div class="navbar-collapse collapse">
            <form id="search-form" class="form-group navbar-form navbar-right" role="search">
                  <div class="form-group">
                    <input type="text" name="q" value=""  id="query" class="form-control" placeholder="搜索" required autocomplete="off" ></input>
                    <input type="submit" class="btn btn-default" value=" Go" ></input>
                  </div>
              </form>
            <ul class="nav navbar-nav">
              <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
              <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
              <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
              <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
              
              <li><a href="https://github.com/javachen" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
              
              
              
              
              
              <li><a href="http://weibo.com/chenzhijun" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
              
              <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
            </ul>
        </div>

        </div><!--/.nav-collapse -->
      </div>
</div>

      <div id="wrap">
          <div class="container">
                 <div id="content">
          <ul class="pager hidden-print">
               
                <li class="previous"><a href="/2015/06/07/spark-configuration.html" title="Spark配置参数"><i class="fa fa-angle-double-left"></i>&nbsp;Spark配置参数</a></li>
                
                
                <li class="next"><a href="/2015/06/10/collaborative-filtering-using-mahout.html" title="使用Mahout实现协同过滤">使用Mahout实现协同过滤&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
                
          </ul>

           <div id="post" class="clearfix">
              <div id="post-title" class="page-header text-center">
                  <h1> Spark On YARN内存分配  </h1>
              </div>
              <p class="text-muted clearfix">
                  <span class="pull-right">2015.06.09 | <a href="#comments">Comments</a></span>
              </p>
              <div id="qr" class="qrcode visible-lg"></div>

              <div id="post-text">
                    <p>本文主要了解Spark On YARN部署模式下的内存分配情况，因为没有深入研究Spark的源代码，所以只能根据日志去看相关的源代码，从而了解“为什么会这样，为什么会那样”。</p>

<h1 id="section">说明</h1>

<p>按照Spark应用程序中的driver分布方式不同，Spark on YARN有两种模式： <code class="highlighter-rouge">yarn-client</code>模式、<code class="highlighter-rouge">yarn-cluster</code>模式。</p>

<p>当在YARN上运行Spark作业，每个Spark executor作为一个YARN容器运行。Spark可以使得多个Tasks在同一个容器里面运行。</p>

<p>下图是yarn-cluster模式的作业执行图，图片来源于网络：</p>

<p><img src="http://www.guozhongxin.com/images/taobao.png" alt="" /></p>

<p>关于Spark On YARN相关的配置参数，请参考<a href="/2015/06/07/spark-configuration.html">Spark配置参数</a>。本文主要讨论内存分配情况，所以只需要关注以下几个内心相关的参数：</p>

<ul>
  <li><code class="highlighter-rouge">spark.driver.memory</code>：默认值512m</li>
  <li><code class="highlighter-rouge">spark.executor.memory</code>：默认值512m</li>
  <li><code class="highlighter-rouge">spark.yarn.am.memory</code>：默认值512m</li>
  <li><code class="highlighter-rouge">spark.yarn.executor.memoryOverhead</code>：值为<code class="highlighter-rouge">executorMemory * 0.07, with minimum of 384</code></li>
  <li><code class="highlighter-rouge">spark.yarn.driver.memoryOverhead</code>：值为<code class="highlighter-rouge">driverMemory * 0.07, with minimum of 384</code></li>
  <li><code class="highlighter-rouge">spark.yarn.am.memoryOverhead</code>：值为<code class="highlighter-rouge">AM memory * 0.07, with minimum of 384</code></li>
</ul>

<p>注意：</p>

<ul>
  <li><code class="highlighter-rouge">--executor-memory/spark.executor.memory</code> 控制 executor 的堆的大小，但是 JVM 本身也会占用一定的堆空间，比如内部的 String 或者直接 byte buffer，<code class="highlighter-rouge">spark.yarn.XXX.memoryOverhead</code>属性决定向 YARN 请求的每个 executor 或dirver或am 的额外堆内存大小，默认值为 <code class="highlighter-rouge">max(384, 0.07 * spark.executor.memory</code>)</li>
  <li>在 executor 执行的时候配置过大的 memory 经常会导致过长的GC延时，64G是推荐的一个 executor 内存大小的上限。</li>
  <li>HDFS client 在大量并发线程时存在性能问题。大概的估计是每个 executor 中最多5个并行的 task 就可以占满写入带宽。</li>
</ul>

<p>另外，因为任务是提交到YARN上运行的，所以YARN中有几个关键参数，参考<a href="/2015/06/05/yarn-memory-and-cpu-configuration.html">YARN的内存和CPU配置</a>：</p>

<ul>
  <li><code class="highlighter-rouge">yarn.app.mapreduce.am.resource.mb</code>：AM能够申请的最大内存，默认值为1536MB</li>
  <li><code class="highlighter-rouge">yarn.nodemanager.resource.memory-mb</code>：nodemanager能够申请的最大内存，默认值为8192MB</li>
  <li><code class="highlighter-rouge">yarn.scheduler.minimum-allocation-mb</code>：调度时一个container能够申请的最小资源，默认值为1024MB</li>
  <li><code class="highlighter-rouge">yarn.scheduler.maximum-allocation-mb</code>：调度时一个container能够申请的最大资源，默认值为8192MB</li>
</ul>

<h1 id="section-1">测试</h1>

<p>Spark集群测试环境为：</p>

<ul>
  <li>master：64G内存，16核cpu</li>
  <li>worker：128G内存，32核cpu</li>
  <li>worker：128G内存，32核cpu</li>
  <li>worker：128G内存，32核cpu</li>
  <li>worker：128G内存，32核cpu</li>
</ul>

<p>注意：YARN集群部署在Spark集群之上的，每一个worker节点上同时部署了一个NodeManager，并且YARN集群中的配置如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>yarn.nodemanager.resource.memory-mb<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>106496<span class="nt">&lt;/value&gt;</span> <span class="c">&lt;!-- 104G --&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>2048<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>106496<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
  <span class="nt">&lt;property&gt;</span>
      <span class="nt">&lt;name&gt;</span>yarn.app.mapreduce.am.resource.mb<span class="nt">&lt;/name&gt;</span>
      <span class="nt">&lt;value&gt;</span>2048<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
</code></pre>
</div>

<p>将spark的日志基本调为DEBUG，并将log4j.logger.org.apache.hadoop设置为WARN建设不必要的输出，修改/etc/spark/conf/log4j.properties：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># Set everything to be logged to the console
</span><span class="py">log4j.rootCategory</span><span class="p">=</span><span class="s">DEBUG, console</span>
<span class="py">log4j.appender.console</span><span class="p">=</span><span class="s">org.apache.log4j.ConsoleAppender</span>
<span class="py">log4j.appender.console.target</span><span class="p">=</span><span class="s">System.err</span>
<span class="py">log4j.appender.console.layout</span><span class="p">=</span><span class="s">org.apache.log4j.PatternLayout</span>
<span class="py">log4j.appender.console.layout.ConversionPattern</span><span class="p">=</span><span class="s">%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n</span>

<span class="c"># Settings to quiet third party logs that are too verbose
</span><span class="py">log4j.logger.org.eclipse.jetty</span><span class="p">=</span><span class="s">WARN</span>
<span class="py">log4j.logger.org.apache.hadoop</span><span class="p">=</span><span class="s">WARN</span>
<span class="py">log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle</span><span class="p">=</span><span class="s">ERROR</span>
<span class="err">log4j.logger.org.apache.spark.repl.SparkIMain$</span><span class="py">exprTyper</span><span class="p">=</span><span class="s">INFO</span>
<span class="err">log4j.logger.org.apache.spark.repl.SparkILoop$</span><span class="py">SparkILoopInterpreter</span><span class="p">=</span><span class="s">INFO</span>
</code></pre>
</div>

<p>接下来是运行测试程序，以官方自带的SparkPi例子为例，<code class="highlighter-rouge">下面主要测试client模式，至于cluster模式请参考下面的过程</code>。运行下面命令：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>spark-submit --class org.apache.spark.examples.SparkPi <span class="se">\</span>
    --master yarn-client  <span class="se">\</span>
    --num-executors 4 <span class="se">\</span>
    --driver-memory 2g <span class="se">\</span>
    --executor-memory 3g <span class="se">\</span>
    --executor-cores 4 <span class="se">\</span>
    /usr/lib/spark/lib/spark-examples-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar <span class="se">\</span>
    100000
</code></pre>
</div>

<p>观察输出日志（无关的日志被略去）：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>15/06/08 13:57:01 INFO SparkContext: Running Spark version 1.3.0
15/06/08 13:57:02 INFO SecurityManager: Changing view acls to: root
15/06/08 13:57:02 INFO SecurityManager: Changing modify acls to: root

15/06/08 13:57:03 INFO MemoryStore: MemoryStore started with capacity 1060.3 MB

15/06/08 13:57:04 DEBUG YarnClientSchedulerBackend: ClientArguments called with: --arg bj03-bi-pro-hdpnamenn:51568 --num-executors 4 --num-executors 4 --executor-memory 3g --executor-memory 3g --executor-cores 4 --executor-cores 4 --name Spark Pi
15/06/08 13:57:04 DEBUG YarnClientSchedulerBackend: [actor] handled message (24.52531 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#864850679]
15/06/08 13:57:05 INFO Client: Requesting a new application from cluster with 4 NodeManagers
15/06/08 13:57:05 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (106496 MB per container)
15/06/08 13:57:05 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
15/06/08 13:57:05 INFO Client: Setting up container launch context for our AM

15/06/08 13:57:07 DEBUG Client: ===============================================================================
15/06/08 13:57:07 DEBUG Client: Yarn AM launch context:
15/06/08 13:57:07 DEBUG Client:     user class: N/A
15/06/08 13:57:07 DEBUG Client:     env:
15/06/08 13:57:07 DEBUG Client:         CLASSPATH -&gt; &lt;CPS&gt;/__spark__.jar&lt;CPS&gt;$HADOOP_CONF_DIR&lt;CPS&gt;$HADOOP_COMMON_HOME/*&lt;CPS&gt;$HADOOP_COMMON_HOME/lib/*&lt;CPS&gt;$HADOOP_HDFS_HOME/*&lt;CPS&gt;$HADOOP_HDFS_HOME/lib/*&lt;CPS&gt;$HADOOP_MAPRED_HOME/*&lt;CPS&gt;$HADOOP_MAPRED_HOME/lib/*&lt;CPS&gt;$HADOOP_YARN_HOME/*&lt;CPS&gt;$HADOOP_YARN_HOME/lib/*&lt;CPS&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*&lt;CPS&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;CPS&gt;:/usr/lib/spark/lib/spark-assembly.jar::/usr/lib/hadoop/lib/*:/usr/lib/hadoop/*:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/*:/usr/lib/hive/lib/*:/usr/lib/flume-ng/lib/*:/usr/lib/paquet/lib/*:/usr/lib/avro/lib/*
15/06/08 13:57:07 DEBUG Client:         SPARK_DIST_CLASSPATH -&gt; :/usr/lib/spark/lib/spark-assembly.jar::/usr/lib/hadoop/lib/*:/usr/lib/hadoop/*:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/*:/usr/lib/hive/lib/*:/usr/lib/flume-ng/lib/*:/usr/lib/paquet/lib/*:/usr/lib/avro/lib/*
15/06/08 13:57:07 DEBUG Client:         SPARK_YARN_CACHE_FILES_FILE_SIZES -&gt; 97237208
15/06/08 13:57:07 DEBUG Client:         SPARK_YARN_STAGING_DIR -&gt; .sparkStaging/application_1433742899916_0001
15/06/08 13:57:07 DEBUG Client:         SPARK_YARN_CACHE_FILES_VISIBILITIES -&gt; PRIVATE
15/06/08 13:57:07 DEBUG Client:         SPARK_USER -&gt; root
15/06/08 13:57:07 DEBUG Client:         SPARK_YARN_MODE -&gt; true
15/06/08 13:57:07 DEBUG Client:         SPARK_YARN_CACHE_FILES_TIME_STAMPS -&gt; 1433743027399
15/06/08 13:57:07 DEBUG Client:         SPARK_YARN_CACHE_FILES -&gt; hdfs://mycluster:8020/user/root/.sparkStaging/application_1433742899916_0001/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar#__spark__.jar
15/06/08 13:57:07 DEBUG Client:     resources:
15/06/08 13:57:07 DEBUG Client:         __spark__.jar -&gt; resource { scheme: "hdfs" host: "mycluster" port: 8020 file: "/user/root/.sparkStaging/application_1433742899916_0001/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar" } size: 97237208 timestamp: 1433743027399 type: FILE visibility: PRIVATE
15/06/08 13:57:07 DEBUG Client:     command:
15/06/08 13:57:07 DEBUG Client:         /bin/java -server -Xmx512m -Djava.io.tmpdir=/tmp '-Dspark.eventLog.enabled=true' '-Dspark.executor.instances=4' '-Dspark.executor.memory=3g' '-Dspark.executor.cores=4' '-Dspark.driver.port=51568' '-Dspark.serializer=org.apache.spark.serializer.KryoSerializer' '-Dspark.driver.appUIAddress=http://bj03-bi-pro-hdpnamenn:4040' '-Dspark.executor.id=&lt;driver&gt;' '-Dspark.kryo.classesToRegister=scala.collection.mutable.BitSet,scala.Tuple2,scala.Tuple1,org.apache.spark.mllib.recommendation.Rating' '-Dspark.driver.maxResultSize=8g' '-Dspark.jars=file:/usr/lib/spark/lib/spark-examples-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar' '-Dspark.driver.memory=2g' '-Dspark.eventLog.dir=hdfs://mycluster:8020/user/spark/applicationHistory' '-Dspark.app.name=Spark Pi' '-Dspark.fileserver.uri=http://X.X.X.X:49172' '-Dspark.tachyonStore.folderName=spark-81ae0186-8325-40f2-867b-65ee7c922357' -Dspark.yarn.app.container.log.dir=&lt;LOG_DIR&gt; org.apache.spark.deploy.yarn.ExecutorLauncher --arg 'bj03-bi-pro-hdpnamenn:51568' --executor-memory 3072m --executor-cores 4 --num-executors  4 1&gt; &lt;LOG_DIR&gt;/stdout 2&gt; &lt;LOG_DIR&gt;/stderr
15/06/08 13:57:07 DEBUG Client: ===============================================================================
</code></pre>
</div>

<p>从<code class="highlighter-rouge">Will allocate AM container, with 896 MB memory including 384 MB overhead</code>日志可以看到，AM占用了<code class="highlighter-rouge">896 MB</code>内存，除掉<code class="highlighter-rouge">384 MB</code>的overhead内存，实际上只有<code class="highlighter-rouge">512 MB</code>，即<code class="highlighter-rouge">spark.yarn.am.memory</code>的默认值，另外可以看到YARN集群有4个NodeManager，每个container最多有106496 MB内存。</p>

<p>Yarn AM launch context启动了一个Java进程，设置的JVM内存为<code class="highlighter-rouge">512m</code>，见<code class="highlighter-rouge">/bin/java -server -Xmx512m</code>。</p>

<p>这里为什么会取默认值呢？查看打印上面这行日志的代码，见org.apache.spark.deploy.yarn.Client：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  <span class="k">private</span> <span class="k">def</span> <span class="n">verifyClusterResources</span><span class="o">(</span><span class="n">newAppResponse</span><span class="k">:</span> <span class="kt">GetNewApplicationResponse</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">maxMem</span> <span class="k">=</span> <span class="n">newAppResponse</span><span class="o">.</span><span class="n">getMaximumResourceCapability</span><span class="o">().</span><span class="n">getMemory</span><span class="o">()</span>
    <span class="n">logInfo</span><span class="o">(</span><span class="s">"Verifying our application has not requested more than the maximum "</span> <span class="o">+</span>
      <span class="n">s</span><span class="s">"memory capability of the cluster ($maxMem MB per container)"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">executorMem</span> <span class="k">=</span> <span class="n">args</span><span class="o">.</span><span class="n">executorMemory</span> <span class="o">+</span> <span class="n">executorMemoryOverhead</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">executorMem</span> <span class="o">&gt;</span> <span class="n">maxMem</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">throw</span> <span class="k">new</span> <span class="nc">IllegalArgumentException</span><span class="o">(</span><span class="n">s</span><span class="s">"Required executor memory (${args.executorMemory}"</span> <span class="o">+</span>
        <span class="n">s</span><span class="s">"+$executorMemoryOverhead MB) is above the max threshold ($maxMem MB) of this cluster!"</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">val</span> <span class="n">amMem</span> <span class="k">=</span> <span class="n">args</span><span class="o">.</span><span class="n">amMemory</span> <span class="o">+</span> <span class="n">amMemoryOverhead</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">amMem</span> <span class="o">&gt;</span> <span class="n">maxMem</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">throw</span> <span class="k">new</span> <span class="nc">IllegalArgumentException</span><span class="o">(</span><span class="n">s</span><span class="s">"Required AM memory (${args.amMemory}"</span> <span class="o">+</span>
        <span class="n">s</span><span class="s">"+$amMemoryOverhead MB) is above the max threshold ($maxMem MB) of this cluster!"</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="n">logInfo</span><span class="o">(</span><span class="s">"Will allocate AM container, with %d MB memory including %d MB overhead"</span><span class="o">.</span><span class="n">format</span><span class="o">(</span>
      <span class="n">amMem</span><span class="o">,</span>
      <span class="n">amMemoryOverhead</span><span class="o">))</span>
  <span class="o">}</span>
</code></pre>
</div>

<p>args.amMemory来自ClientArguments类，这个类中会校验输出参数：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  <span class="k">private</span> <span class="k">def</span> <span class="n">validateArgs</span><span class="o">()</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">numExecutors</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">throw</span> <span class="k">new</span> <span class="nc">IllegalArgumentException</span><span class="o">(</span>
        <span class="s">"You must specify at least 1 executor!\n"</span> <span class="o">+</span> <span class="n">getUsageMessage</span><span class="o">())</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">executorCores</span> <span class="o">&lt;</span> <span class="n">sparkConf</span><span class="o">.</span><span class="n">getInt</span><span class="o">(</span><span class="s">"spark.task.cpus"</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span> <span class="o">{</span>
      <span class="k">throw</span> <span class="k">new</span> <span class="nc">SparkException</span><span class="o">(</span><span class="s">"Executor cores must not be less than "</span> <span class="o">+</span>
        <span class="s">"spark.task.cpus."</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">isClusterMode</span><span class="o">)</span> <span class="o">{</span>
      <span class="k">for</span> <span class="o">(</span><span class="n">key</span> <span class="k">&lt;-</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">amMemKey</span><span class="o">,</span> <span class="n">amMemOverheadKey</span><span class="o">,</span> <span class="n">amCoresKey</span><span class="o">))</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">sparkConf</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="n">key</span><span class="o">))</span> <span class="o">{</span>
          <span class="n">println</span><span class="o">(</span><span class="n">s</span><span class="s">"$key is set but does not apply in cluster mode."</span><span class="o">)</span>
        <span class="o">}</span>
      <span class="o">}</span>
      <span class="n">amMemory</span> <span class="k">=</span> <span class="n">driverMemory</span>
      <span class="n">amCores</span> <span class="k">=</span> <span class="n">driverCores</span>
    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
      <span class="k">for</span> <span class="o">(</span><span class="n">key</span> <span class="k">&lt;-</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">driverMemOverheadKey</span><span class="o">,</span> <span class="n">driverCoresKey</span><span class="o">))</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">sparkConf</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="n">key</span><span class="o">))</span> <span class="o">{</span>
          <span class="n">println</span><span class="o">(</span><span class="n">s</span><span class="s">"$key is set but does not apply in client mode."</span><span class="o">)</span>
        <span class="o">}</span>
      <span class="o">}</span>
      <span class="n">sparkConf</span><span class="o">.</span><span class="n">getOption</span><span class="o">(</span><span class="n">amMemKey</span><span class="o">)</span>
        <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Utils</span><span class="o">.</span><span class="n">memoryStringToMb</span><span class="o">)</span>
        <span class="o">.</span><span class="n">foreach</span> <span class="o">{</span> <span class="n">mem</span> <span class="k">=&gt;</span> <span class="n">amMemory</span> <span class="k">=</span> <span class="n">mem</span> <span class="o">}</span>
      <span class="n">sparkConf</span><span class="o">.</span><span class="n">getOption</span><span class="o">(</span><span class="n">amCoresKey</span><span class="o">)</span>
        <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toInt</span><span class="o">)</span>
        <span class="o">.</span><span class="n">foreach</span> <span class="o">{</span> <span class="n">cores</span> <span class="k">=&gt;</span> <span class="n">amCores</span> <span class="k">=</span> <span class="n">cores</span> <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>
</code></pre>
</div>

<p>从上面代码可以看到当 isClusterMode 为true时，则args.amMemory值为driverMemory的值；否则，则从<code class="highlighter-rouge">spark.yarn.am.memory</code>中取，如果没有设置该属性，则取默认值512m。isClusterMode 为true的条件是 userClass 不为空，<code class="highlighter-rouge">def isClusterMode: Boolean = userClass != null</code>，即输出参数需要有<code class="highlighter-rouge">--class</code>参数，而从下面日志可以看到ClientArguments的输出参数中并没有该参数。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>15/06/08 13:57:04 DEBUG YarnClientSchedulerBackend: ClientArguments called with: --arg bj03-bi-pro-hdpnamenn:51568 --num-executors 4 --num-executors 4 --executor-memory 3g --executor-memory 3g --executor-cores 4 --executor-cores 4 --name Spark Pi
</code></pre>
</div>

<p>故，要想设置AM申请的内存值，要么使用cluster模式，要么在client模式中，是有<code class="highlighter-rouge">--conf</code>手动设置<code class="highlighter-rouge">spark.yarn.am.memory</code>属性，例如：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>spark-submit --class org.apache.spark.examples.SparkPi <span class="se">\</span>
    --master yarn-client  <span class="se">\</span>
    --num-executors 4 <span class="se">\</span>
    --driver-memory 2g <span class="se">\</span>
    --executor-memory 3g <span class="se">\</span>
    --executor-cores 4 <span class="se">\</span>
    --conf spark.yarn.am.memory<span class="o">=</span>1024m <span class="se">\</span>
    /usr/lib/spark/lib/spark-examples-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar <span class="se">\</span>
    100000
</code></pre>
</div>

<p>打开YARN管理界面，可以看到：</p>

<p>a. Spark Pi 应用启动了5个Container，使用了18G内存、5个CPU core</p>

<p><img src="/static/images/hadoop/memory-in-spark-on-yarn-1.jpg" alt="" /></p>

<p>b. YARN为AM启动了一个Container，占用内存为2048M</p>

<p><img src="/static/images/hadoop/memory-in-spark-on-yarn-2.jpg" alt="" /></p>

<p>c. YARN启动了4个Container运行任务，每一个Container占用内存为4096M</p>

<p><img src="/static/images/hadoop/memory-in-spark-on-yarn-3.jpg" alt="" /></p>

<p>为什么会是<code class="highlighter-rouge">2G +4G *4=18G</code>呢？第一个Container只申请了2G内存，是因为我们的程序只为AM申请了512m内存，而<code class="highlighter-rouge">yarn.scheduler.minimum-allocation-mb</code>参数决定了最少要申请2G内存。至于其余的Container，我们设置了executor-memory内存为3G，为什么每一个Container占用内存为4096M呢？</p>

<p>为了找出规律，多测试几组数据，分别测试并收集executor-memory为3G、4G、5G、6G时每个executor对应的Container内存申请情况：</p>

<ul>
  <li>executor-memory=3g：2G+4G * 4=18G</li>
  <li>executor-memory=4g：2G+6G * 4=26G</li>
  <li>executor-memory=5g：2G+6G * 4=26G</li>
  <li>executor-memory=6g：2G+8G * 4=34G</li>
</ul>

<p>关于这个问题，我是查看源代码，根据org.apache.spark.deploy.yarn.ApplicationMaster -&gt; YarnRMClient -&gt; YarnAllocator的类查找路径找到YarnAllocator中有这样一段代码：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  <span class="c1">// Executor memory in MB.</span>
  <span class="kd">protected</span> <span class="n">val</span> <span class="n">executorMemory</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="na">executorMemory</span>
  <span class="c1">// Additional memory overhead.</span>
  <span class="kd">protected</span> <span class="n">val</span> <span class="nl">memoryOverhead:</span> <span class="n">Int</span> <span class="o">=</span> <span class="n">sparkConf</span><span class="o">.</span><span class="na">getInt</span><span class="o">(</span><span class="s">"spark.yarn.executor.memoryOverhead"</span><span class="o">,</span>
    <span class="n">math</span><span class="o">.</span><span class="na">max</span><span class="o">((</span><span class="n">MEMORY_OVERHEAD_FACTOR</span> <span class="o">*</span> <span class="n">executorMemory</span><span class="o">).</span><span class="na">toInt</span><span class="o">,</span> <span class="n">MEMORY_OVERHEAD_MIN</span><span class="o">))</span>
  <span class="c1">// Number of cores per executor.</span>
  <span class="kd">protected</span> <span class="n">val</span> <span class="n">executorCores</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="na">executorCores</span>
  <span class="c1">// Resource capability requested for each executors</span>
  <span class="kd">private</span> <span class="n">val</span> <span class="n">resource</span> <span class="o">=</span> <span class="n">Resource</span><span class="o">.</span><span class="na">newInstance</span><span class="o">(</span><span class="n">executorMemory</span> <span class="o">+</span> <span class="n">memoryOverhead</span><span class="o">,</span> <span class="n">executorCores</span><span class="o">)</span>
</code></pre>
</div>

<p>因为没有具体的去看YARN的源代码，所以这里猜测Container的大小是根据<code class="highlighter-rouge">executorMemory + memoryOverhead</code>计算出来的，大概的规则是每一个Container的大小必须为<code class="highlighter-rouge">yarn.scheduler.minimum-allocation-mb</code>值的整数倍，当<code class="highlighter-rouge">executor-memory=3g</code>时，<code class="highlighter-rouge">executorMemory + memoryOverhead</code>为3G+384M=3456M，需要申请的Container大小为<code class="highlighter-rouge">yarn.scheduler.minimum-allocation-mb</code> * 2 =4096m=4G，其他依此类推。</p>

<blockquote>
  <p>注意：</p>

  <ul>
    <li>Yarn always rounds up memory requirement to multiples of <code class="highlighter-rouge">yarn.scheduler.minimum-allocation-mb</code>, which by default is 1024 or 1GB.</li>
    <li>Spark adds an <code class="highlighter-rouge">overhead</code> to <code class="highlighter-rouge">SPARK_EXECUTOR_MEMORY/SPARK_DRIVER_MEMORY</code> before asking Yarn for the amount.</li>
  </ul>
</blockquote>

<p>另外，需要注意memoryOverhead的计算方法，当executorMemory的值很大时，memoryOverhead的值相应会变大，这个时候就不是384m了，相应的Container申请的内存值也变大了，例如：当executorMemory设置为90G时，memoryOverhead值为<code class="highlighter-rouge">math.max(0.07 * 90G, 384m)=6.3G</code>，其对应的Container申请的内存为98G。</p>

<p>回头看看给AM对应的Container分配2G内存原因，512+384=896，小于2G，故分配2G，你可以在设置<code class="highlighter-rouge">spark.yarn.am.memory</code>的值之后再来观察。</p>

<p>打开Spark的管理界面 <a href="http://ip:4040">http://ip:4040</a> ，可以看到driver和Executor中内存的占用情况：</p>

<p><img src="/static/images/hadoop/memory-in-spark-on-yarn-4.jpg" alt="" /></p>

<p>从上图可以看到Executor占用了1566.7 MB内存，这是怎样计算出来的？参考<a href="http://www.wdong.org/wordpress/blog/2015/01/08/spark-on-yarn-where-have-all-my-memory-gone/">Spark on Yarn: Where Have All the Memory Gone?</a>这篇文章，totalExecutorMemory的计算方式为：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c1">//yarn/common/src/main/scala/org/apache/spark/deploy/yarn/YarnSparkHadoopUtil.scala
</span>  <span class="k">val</span> <span class="nc">MEMORY_OVERHEAD_FACTOR</span> <span class="k">=</span> <span class="mf">0.07</span>
  <span class="k">val</span> <span class="nc">MEMORY_OVERHEAD_MIN</span> <span class="k">=</span> <span class="mi">384</span>

<span class="c1">//yarn/common/src/main/scala/org/apache/spark/deploy/yarn/YarnAllocator.scala
</span>  <span class="k">protected</span> <span class="k">val</span> <span class="n">memoryOverhead</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="n">sparkConf</span><span class="o">.</span><span class="n">getInt</span><span class="o">(</span><span class="s">"spark.yarn.executor.memoryOverhead"</span><span class="o">,</span>
    <span class="n">math</span><span class="o">.</span><span class="n">max</span><span class="o">((</span><span class="nc">MEMORY_OVERHEAD_FACTOR</span> <span class="o">*</span> <span class="n">executorMemory</span><span class="o">).</span><span class="n">toInt</span><span class="o">,</span> <span class="nc">MEMORY_OVERHEAD_MIN</span><span class="o">))</span>
<span class="o">......</span>
      <span class="k">val</span> <span class="n">totalExecutorMemory</span> <span class="k">=</span> <span class="n">executorMemory</span> <span class="o">+</span> <span class="n">memoryOverhead</span>
      <span class="n">numPendingAllocate</span><span class="o">.</span><span class="n">addAndGet</span><span class="o">(</span><span class="n">missing</span><span class="o">)</span>
      <span class="n">logInfo</span><span class="o">(</span><span class="n">s</span><span class="s">"Will allocate $missing executor containers, each with $totalExecutorMemory MB "</span> <span class="o">+</span>
        <span class="n">s</span><span class="s">"memory including $memoryOverhead MB overhead"</span><span class="o">)</span>
</code></pre>
</div>

<p>这里我们给executor-memory设置的3G内存，memoryOverhead的值为<code class="highlighter-rouge">math.max(0.07 * 3072, 384)=384</code>，其最大可用内存通过下面代码来计算：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c1">//core/src/main/scala/org/apache/spark/storage/BlockManager.scala
</span><span class="cm">/** Return the total amount of storage memory available. */</span>
<span class="k">private</span> <span class="k">def</span> <span class="n">getMaxMemory</span><span class="o">(</span><span class="n">conf</span><span class="k">:</span> <span class="kt">SparkConf</span><span class="o">)</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">memoryFraction</span> <span class="k">=</span> <span class="n">conf</span><span class="o">.</span><span class="n">getDouble</span><span class="o">(</span><span class="s">"spark.storage.memoryFraction"</span><span class="o">,</span> <span class="mf">0.6</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">safetyFraction</span> <span class="k">=</span> <span class="n">conf</span><span class="o">.</span><span class="n">getDouble</span><span class="o">(</span><span class="s">"spark.storage.safetyFraction"</span><span class="o">,</span> <span class="mf">0.9</span><span class="o">)</span>
  <span class="o">(</span><span class="nc">Runtime</span><span class="o">.</span><span class="n">getRuntime</span><span class="o">.</span><span class="n">maxMemory</span> <span class="o">*</span> <span class="n">memoryFraction</span> <span class="o">*</span> <span class="n">safetyFraction</span><span class="o">).</span><span class="n">toLong</span>
<span class="o">}</span>
</code></pre>
</div>

<p>即，对于executor-memory设置3G时，executor内存占用大约为 3072m * 0.6 * 0.9 = 1658.88m，注意：实际上是应该乘以<code class="highlighter-rouge">Runtime.getRuntime.maxMemory</code>的值，该值小于3072m。</p>

<p>上图中driver占用了1060.3 MB，此时driver-memory的值是位2G，故driver中存储内存占用为：2048m * 0.6 * 0.9 =1105.92m，注意：实际上是应该乘以<code class="highlighter-rouge">Runtime.getRuntime.maxMemory</code>的值，该值小于2048m。</p>

<p>这时候，查看worker节点CoarseGrainedExecutorBackend进程启动脚本：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>jps
46841 Worker
21894 CoarseGrainedExecutorBackend
9345
21816 ExecutorLauncher
43369
24300 NodeManager
38012 JournalNode
36929 QuorumPeerMain
22909 Jps

<span class="gp">$ </span>ps -ef|grep 21894
nobody   21894 21892 99 17:28 ?        00:04:49 /usr/java/jdk1.7.0_71/bin/java -server -XX:OnOutOfMemoryError<span class="o">=</span><span class="nb">kill</span> %p -Xms3072m -Xmx3072m  -Djava.io.tmpdir<span class="o">=</span>/data/yarn/local/usercache/root/appcache/application_1433742899916_0069/container_1433742899916_0069_01_000003/tmp -Dspark.driver.port<span class="o">=</span>60235 -Dspark.yarn.app.container.log.dir<span class="o">=</span>/data/yarn/logs/application_1433742899916_0069/container_1433742899916_0069_01_000003 org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url akka.tcp://sparkDriver@bj03-bi-pro-hdpnamenn:60235/user/CoarseGrainedScheduler --executor-id 2 --hostname X.X.X.X --cores 4 --app-id application_1433742899916_0069 --user-class-path file:/data/yarn/local/usercache/root/appcache/application_1433742899916_0069/container_1433742899916_0069_01_000003/__app__.jar
</code></pre>
</div>

<p>可以看到每个CoarseGrainedExecutorBackend进程分配的内存为3072m，如果我们想查看每个executor的jvm运行情况，可以开启jmx。在/etc/spark/conf/spark-defaults.conf中添加下面一行代码：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="err">spark.executor.extraJavaOptions</span> <span class="err">-</span><span class="py">Dcom.sun.management.jmxremote.port</span><span class="p">=</span><span class="s">1099 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false</span>
</code></pre>
</div>

<p>然后，通过jconsole监控jvm堆内存运行情况，这样方便调试内存大小。</p>

<h1 id="section-2">总结</h1>

<p>由上可知，在client模式下，AM对应的Container内存由<code class="highlighter-rouge">spark.yarn.am.memory</code>加上<code class="highlighter-rouge">spark.yarn.am.memoryOverhead</code>来确定，executor加上spark.<code class="highlighter-rouge">yarn.executor.memoryOverhead</code>的值之后确定对应Container需要申请的内存大小，driver和executor的内存加上<code class="highlighter-rouge">spark.yarn.driver.memoryOverhead</code>或<code class="highlighter-rouge">spark.yarn.executor.memoryOverhead</code>的值之后再乘以0.54确定storage memory内存大小。在YARN中，Container申请的内存大小必须为<code class="highlighter-rouge">yarn.scheduler.minimum-allocation-mb</code>的整数倍。</p>

<p>下面这张图展示了Spark on YARN 内存结构，图片来自<a href="http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/">How-to: Tune Your Apache Spark Jobs (Part 2)</a>：</p>

<p><img src="http://blog.cloudera.com/wp-content/uploads/2015/03/spark-tuning2-f1.png" alt="" /></p>

<p>至于cluster模式下的分析，请参考上面的过程。希望这篇文章对你有所帮助！</p>

<h1 id="section-3">参考文章</h1>

<ul>
  <li><a href="http://blog.csdn.net/book_mmicky/article/details/25714287">Spark1.0.0 on YARN 模式部署</a></li>
  <li><a href="http://www.wdong.org/wordpress/blog/2015/01/08/spark-on-yarn-where-have-all-my-memory-gone/">Spark on Yarn: Where Have All the Memory Gone?</a></li>
  <li><a href="https://www.zybuluo.com/xiaop1987/note/102894">Apache Spark Jobs 性能调优（二）</a></li>
</ul>


                    <br/>
                    <div class="well">
                        原创文章，转载请注明： 转载自<a href="http://blog.javachen.com">JavaChen Blog</a>，作者：<a href="http://blog.javachen.com/about.html">JavaChen</a><br/>
                        本文链接地址：<a href="/2015/06/09/memory-in-spark-on-yarn.html">http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html</a><br/>
                        本文基于<a target="_blank" title="Creative Commons Attribution 2.5 China Mainland License" href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。
                        如您有任何疑问或者授权方面的协商，请邮件联系我</a>。
                    </div>
                    <div class="col-md-6">
                      <p class="text-success hidden-print"><i class="fa fa-external-link"></i> <a href="/2015/06/09/memory-in-spark-on-yarn.html">Spark On YARN内存分配</a></p>
                    </div>
                    <div class="col-md-6">
                       <p class="meta hidden-print pull-right">
                        
                            <i class="fa fa-folder-open"></i>
                            
                            <a class="btn btn-default btn-sm" href="/categories.html#spark">spark</a>
                          
                        
                        
                            <i class="fa fa-tags"></i>
                            
                            <a class="btn btn-default btn-sm" href="/tags.html#spark">spark</a>
                          
                        </p>
                    </div>
               </div><!--#post-text-->
          </div><!--#post-->
      </div> <!--#content-->

      <div id="post-comment" class="hidden-print">
      
<div id="comments">
  <div class="ds-thread" data-thread-key="/2015/06/09/memory-in-spark-on-yarn.html" data-url="http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html" data-title="Spark On YARN内存分配"></div>
</div>



      </div>


          </div>
          <a href="#" class="btn back-to-top btn-dark btn-fixed-bottom hidden-print"><i class="fa fa-chevron-up"></i></a>
      </div>
      <div id="footer">
          <div class="container hidden-print">
              <p class="text-center"><i class="fa fa-copyright"></i> 2016 JavaChen Blog. Theme designed by <a href="/about.html" target="_blank" title="JavaChen Blog
">JavaChen</a> with <a href="https://github.com/mojombo/jekyll/">Jekyll</a>, <a href="http://twitter.github.com/bootstrap/">Bootstrap</a> and <a href="http://fortawesome.github.com/Font-Awesome/">Font Awesome</a>.
  	            
                    <script type="text/javascript" src="http://tajs.qq.com/stats?sId=52032901" charset="UTF-8"></script>
            

            
    </p>
          </div>
      </div>

      <script type="text/javascript" src="/static/contrib/jquery/jquery.min.js"></script>
      <script type="text/javascript" src="/static/contrib/bootstrap/js/bootstrap.min.js"></script>
      <script type="text/javascript" src="/static/contrib/qrcode/jquery.qrcode.min.js"></script>
      <script type="text/javascript" src="/static/contrib/showup/showup.js"></script>
      <script type="text/javascript" src="/static/js/core.js"></script>
      
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"javachen"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
      

      <script type="text/javascript">
      $('#qr').qrcode({
          width: 128,
          height: 128,
          text: 'http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html'
      });
      </script>
  </body>
</html>
