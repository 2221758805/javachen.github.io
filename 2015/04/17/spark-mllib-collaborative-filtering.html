<!DOCTYPE html>
<html lang="zh-cn">
        <head>
      <meta charset="utf-8"/>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
      <title>Spark MLlib中的协同过滤 - JavaChen Blog</title>
      <meta name="author" content="yuke"/>
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
      <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
      <link rel="canonical" href="http://blog.javachen.com/2015/04/17/spark-mllib-collaborative-filtering.html" />

      <link rel="stylesheet" href="/static/contrib/bootstrap/css/bootstrap.min.css" media="all" />
      <link rel="stylesheet" href="/static/css/style.css" media="all" />
      <link rel="stylesheet" href="/static/css/pygments.css" media="all" />
      <link rel="stylesheet" href="/static/contrib/font-awesome/css/font-awesome.min.css" media="all" />
      <link rel="stylesheet" type="text/css" href="/static/contrib/showup/showup.css" />

      <!-- atom & rss feed -->
      <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="JavaChen Blog RSS Feed" />
      <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="JavaChen Blog ATOM Feed" />

        <!-- fav and touch icons  -->
        <!-- Update these with your own images
        <link rel="shortcut icon" href="images/favicon.ico">
        <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
        <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
        -->

      <meta name="renderer" content="webkit|ie-stand">
      <meta name="baidu-site-verification" content="3HAhaWRiyR" />
      <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
      <meta name="sogou_site_verification" content="ofwXWFdthV"/>
      <meta property="wb:webmaster" content="b6081b2b8ab84c60" />
    </head>

    <body>
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">JavaChen Blog</a>
        </div>
        <div class="navbar-collapse collapse">
            <form id="search-form" class="form-group navbar-form navbar-right" role="search">
                  <div class="form-group">
                    <input type="text" name="q" value=""  id="query" class="form-control" placeholder="搜索" required autocomplete="off" ></input>
                    <input type="submit" class="btn btn-default" value=" Go" ></input>
                  </div>
              </form>
            <ul class="nav navbar-nav">
              <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
              <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
              <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
              <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
              
              <li><a href="https://github.com/javachen" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
              
              
              
              <li><a href="https://twitter.com/java_chen" target="_blank" title="twitter"><span class="fa fa-twitter fa-2x"></span></a></li>
              
              
              
              <li><a href="http://weibo.com/chenzhijun" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
              
              <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
            </ul>
        </div>

        </div><!--/.nav-collapse -->
      </div>
</div>

      <div id="wrap">
          <div class="container">
                 <div id="content">
          <ul class="pager hidden-print">
               
                <li class="previous"><a href="/2015/04/03/spark-sql-datasource.html" title="Spark SQL中的数据源"><i class="fa fa-angle-double-left"></i>&nbsp;Spark SQL中的数据源</a></li>
                
                
                <li class="next"><a href="/2015/04/20/basic-of-scala.html" title="Scala基本语法和概念">Scala基本语法和概念&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
                
          </ul>

           <div id="post" class="clearfix">
              <div id="post-title" class="page-header text-center">
                  <h1> Spark MLlib中的协同过滤  </h1>
              </div>
              <p class="text-muted clearfix">
                  <span class="pull-right">2015.04.17 | <a href="#comments">Comments</a></span>
              </p>
              <div id="qr" class="qrcode visible-lg"></div>

              <div id="post-text">
                    <p>本文主要通过Spark官方的例子理解ALS协同过滤算法的原理和编码过程，然后通过对电影进行推荐来熟悉一个完整的推荐过程。</p>

<h1 id="section">协同过滤</h1>

<p><a href="http://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering">协同过滤</a>常被应用于推荐系统，旨在补充用户-商品关联矩阵中所缺失的部分。MLlib当前支持基于模型的协同过滤，其中用户和商品通过一小组隐语义因子进行表达，并且这些因子也用于预测缺失的元素。Spark MLlib实现了<a href="http://dl.acm.org/citation.cfm?id=1608614">交替最小二乘法</a>(ALS) 来学习这些隐性语义因子。</p>

<p>在 MLlib 中的实现类为org.apache.spark.mllib.recommendation.ALS.scala，其有如下的参数:</p>

<ul>
  <li><code>numUserBlocks</code>：是用于并行化计算的分块个数 (设置为-1，为自动配置)。</li>
  <li><code>numProductBlocks</code>：是用于并行化计算的分块个数 (设置为-1，为自动配置)。</li>
  <li><code>rank</code>：是模型中隐语义因子的个数。</li>
  <li><code>iterations</code>：是迭代的次数，推荐值：10-20。</li>
  <li><code>lambda</code>：惩罚函数的因数，是ALS的正则化参数，推荐值：0.01。</li>
  <li><code>implicitPrefs</code>：决定了是用显性反馈ALS的版本还是用适用隐性反馈数据集的版本。</li>
  <li><code>alpha</code>：是一个针对于隐性反馈 ALS 版本的参数，这个参数决定了偏好行为强度的基准。</li>
  <li><code>seed</code>：随机种子</li>
</ul>

<p>可以调整这些参数，不断优化结果，使均方差变小。比如：iterations越多，lambda较小，均方差会较小，推荐结果较优。</p>

<p>提供以下方法：</p>

<pre><code class="language-scala">def run(ratings: RDD[Rating]): MatrixFactorizationModel

def train(ratings: RDD[Rating],rank: Int,iterations: Int,lambda: Double,blocks: Int,seed: Long): MatrixFactorizationModel
def train(ratings: RDD[Rating],rank: Int,iterations: Int,lambda: Double,blocks: Int): MatrixFactorizationModel
def train(ratings: RDD[Rating], rank: Int, iterations: Int, lambda: Double): MatrixFactorizationModel
def train(ratings: RDD[Rating], rank: Int, iterations: Int): MatrixFactorizationModel

def trainImplicit(ratings: RDD[Rating],rank: Int,iterations: Int,lambda: Double,blocks: Int,alpha: Double,seed: Long): MatrixFactorizationModel
def trainImplicit(ratings: RDD[Rating],rank: Int,iterations: Int,lambda: Double,blocks: Int,alpha: Double): MatrixFactorizationModel
def trainImplicit(ratings: RDD[Rating], rank: Int, iterations: Int, lambda: Double, alpha: Double): MatrixFactorizationModel
def trainImplicit(ratings: RDD[Rating], rank: Int, iterations: Int): MatrixFactorizationModel
</code></pre>

<p>以上所有方法需要一个参数Rating，其为一个包括三个元素的 case class：</p>

<pre><code class="language-scala">case class Rating(user: Int, product: Int, rating: Double)
</code></pre>

<p>另外，以上方法均返回MatrixFactorizationModel类型的对象，提供以下方法：</p>

<pre><code class="language-scala">/** Predict the rating of one user for one product. */
def predict(user: Int, product: Int): Double

/**Predict the rating of many users for many products.*/
def predict(usersProducts: RDD[(Int, Int)]): RDD[Rating]

// Recommends products to a user.
def recommendProducts(user: Int, num: Int): Array[Rating]

//Recommends users to a product.
def recommendUsers(product: Int, num: Int): Array[Rating]

def save(sc: SparkContext, path: String): Unit

def load(sc: SparkContext, path: String): MatrixFactorizationModel =
</code></pre>

<h2 id="vs-">隐性反馈 vs 显性反馈</h2>

<p>基于矩阵分解的协同过滤的标准方法一般将用户商品矩阵中的元素作为用户对商品的显性偏好。<br />
在许多的现实生活中的很多场景中，我们常常只能接触到隐性的反馈（例如游览，点击，购买，喜欢，分享等等）在 MLlib 中所用到的处理这种数据的方法来源于文献： <a href="http://labs.yahoo.com/files/HuKorenVolinsky-ICDM08.pdf">Collaborative Filtering for Implicit Feedback Datasets</a>。 本质上，这个方法将数据作为二元偏好值和偏好强度的一个结合，而不是对评分矩阵直接进行建模。因此，评价就不是与用户对商品的显性评分而是和所观察到的用户偏好强度关联了起来。然后，这个模型将尝试找到隐语义因子来预估一个用户对一个商品的偏好。</p>

<h1 id="section-1">代码示例</h1>

<p>下面例子来自<a href="http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html">http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html</a>，并做了稍许修改。</p>

<h2 id="scala-">Scala 示例</h2>

<p>为了测试简单，使用Spark本地运行模式进行测试。下面代码可以在spark-shell中运行：</p>

<pre><code class="language-scala">import org.apache.spark.mllib.recommendation.ALS
import org.apache.spark.mllib.recommendation.MatrixFactorizationModel
import org.apache.spark.mllib.recommendation.Rating

// Load and parse the data
val data = sc.textFile("data/mllib/als/test.data")
val ratings = data.map(_.split(',') match { case Array(user, item, rate) =&gt;
    Rating(user.toInt, item.toInt, rate.toDouble)
  })

// Build the recommendation model using ALS
val rank = 10
val numIterations = 20
val model = ALS.train(ratings, rank, numIterations, 0.01)

// Evaluate the model on rating data
val usersProducts = ratings.map { case Rating(user, product, rate) =&gt;
  (user, product)
}
val predictions = 
  model.predict(usersProducts).map { case Rating(user, product, rate) =&gt; 
    ((user, product), rate)
  }
val ratesAndPreds = ratings.map { case Rating(user, product, rate) =&gt; 
  ((user, product), rate)
}.join(predictions)
val MSE = ratesAndPreds.map { case ((user, product), (r1, r2)) =&gt; 
  val err = (r1 - r2)
  err * err
}.mean()
println("Mean Squared Error = " + MSE)

// Save and load model
model.save(sc, "myModelPath")
val sameModel = MatrixFactorizationModel.load(sc, "myModelPath")
</code></pre>

<h2 id="java">Java示例</h2>

<pre><code class="language-java">import scala.Tuple2;

import org.apache.spark.api.java.*;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.mllib.recommendation.ALS;
import org.apache.spark.mllib.recommendation.MatrixFactorizationModel;
import org.apache.spark.mllib.recommendation.Rating;
import org.apache.spark.SparkConf;

public class JavaALS {
  public static void main(String[] args) {
    SparkConf conf = new SparkConf().setAppName("Collaborative Filtering Example");
    JavaSparkContext sc = new JavaSparkContext(conf);

    // Load and parse the data
    String path = "data/mllib/als/test.data";
    JavaRDD&lt;String&gt; data = sc.textFile(path);
    JavaRDD&lt;Rating&gt; ratings = data.map(
      new Function&lt;String, Rating&gt;() {
        public Rating call(String s) {
          String[] sarray = s.split(",");
          return new Rating(Integer.parseInt(sarray[0]), Integer.parseInt(sarray[1]), 
                            Double.parseDouble(sarray[2]));
        }
      }
    );

    // Build the recommendation model using ALS
    int rank = 10;
    int numIterations = 20;
    float lambda = 0.01;
    MatrixFactorizationModel model = ALS.train(JavaRDD.toRDD(ratings), rank, numIterations, lambda); 

    // Evaluate the model on rating data
    JavaRDD&lt;Tuple2&lt;Object, Object&gt;&gt; userProducts = ratings.map(
      new Function&lt;Rating, Tuple2&lt;Object, Object&gt;&gt;() {
        public Tuple2&lt;Object, Object&gt; call(Rating r) {
          return new Tuple2&lt;Object, Object&gt;(r.user(), r.product());
        }
      }
    );
    JavaPairRDD&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt; predictions = JavaPairRDD.fromJavaRDD(
      model.predict(JavaRDD.toRDD(userProducts)).toJavaRDD().map(
        new Function&lt;Rating, Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt;&gt;() {
          public Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt; call(Rating r){
            return new Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt;(
              new Tuple2&lt;Integer, Integer&gt;(r.user(), r.product()), r.rating());
          }
        }
    ));
    JavaRDD&lt;Tuple2&lt;Double, Double&gt;&gt; ratesAndPreds = 
      JavaPairRDD.fromJavaRDD(ratings.map(
        new Function&lt;Rating, Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt;&gt;() {
          public Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt; call(Rating r){
            return new Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt;(
              new Tuple2&lt;Integer, Integer&gt;(r.user(), r.product()), r.rating());
          }
        }
    )).join(predictions).values();
    double MSE = JavaDoubleRDD.fromRDD(ratesAndPreds.map(
      new Function&lt;Tuple2&lt;Double, Double&gt;, Object&gt;() {
        public Object call(Tuple2&lt;Double, Double&gt; pair) {
          Double err = pair._1() - pair._2();
          return err * err;
        }
      }
    ).rdd()).mean();
    System.out.println("Mean Squared Error = " + MSE);
  }
}
</code></pre>

<h2 id="python">Python示例</h2>

<p>下面代码可以在 pyspark 中运行下面代码：</p>

<pre><code class="language-python">from pyspark.mllib.recommendation import ALS
from numpy import array

# Load and parse the data
data = sc.textFile("data/mllib/als/test.data")
ratings = data.map(lambda line: array([float(x) for x in line.split(',')]))

# Build the recommendation model using Alternating Least Squares
rank = 10
numIterations = 20
model = ALS.train(ratings, rank, numIterations)

# Evaluate the model on training data
testdata = ratings.map(lambda p: (int(p[0]), int(p[1])))
predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))
ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)
MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).reduce(lambda x, y: x + y)/ratesAndPreds.count()
print("Mean Squared Error = " + str(MSE))
</code></pre>

<h1 id="section-2">总结</h1>

<p>使用Spark MLlib的ALS算法进行协同过滤，首先需要了解推荐的过程，然后需要根据测试不断修改训练测试，建立合理的模型，最后再给用户进行推荐商品，保存推荐结果。</p>

<p>另外，在网上找到一些Spark做推荐的项目：</p>

<ul>
  <li>提供Restfull接口的实时推荐：<a href="https://github.com/OndraFiedler/spark-recommender">https://github.com/OndraFiedler/spark-recommender</a></li>
  <li>spark-elasticsearch-mllib：<a href="https://github.com/ebiznext/spark-elasticsearch-mllib">https://github.com/ebiznext/spark-elasticsearch-mllib</a></li>
  <li>Beyond Piwik Web Analytics：<a href="https://github.com/skrusche63/spark-piwik">https://github.com/skrusche63/spark-piwik</a></li>
  <li>Serves predictions via a REST API：<a href="https://github.com/SeldonIO/seldon-server">https://github.com/SeldonIO/seldon-server</a></li>
  <li><a href="https://github.com/zhuixun/learningspark">https://github.com/zhuixun/learningspark</a></li>
  <li>Spark-Movie-Recommendation：<a href="https://github.com/yuriy-voderatskiy/Spark-Movie-Recommendation">https://github.com/yuriy-voderatskiy/Spark-Movie-Recommendation</a></li>
</ul>

<p>更多关于推荐相关的资源可以参考<a href="/2015/03/30/reading-list-2015-03.html">Reading List 2015-03</a>。</p>

<h1 id="section-3">参考文章</h1>

<ul>
  <li><a href="https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html">Movie Recommendation with MLlib</a></li>
  <li><a href="http://blog.csdn.net/shifenglov/article/details/43795597">Spark MLlib系列(二):基于协同过滤的电影推荐系统</a></li>
  <li><a href="https://github.com/gaapt/als_recom/blob/master/ALSBenchmarkSpark%2Fsrc%2Fmain%2Fscala%2FALSBenchmark.scala">ALSBenchmark.scala</a></li>
</ul>

                    <br/>
                    <div class="well">
                        原创文章，转载请注明： 转载自<a href="http://blog.javachen.com">JavaChen Blog</a>，作者：<a href="http://blog.javachen.com/about.html">yuke</a><br/>
                        本文链接地址：<a href="/2015/04/17/spark-mllib-collaborative-filtering.html">http://blog.javachen.com/2015/04/17/spark-mllib-collaborative-filtering.html</a><br/>
                        本文基于<a target="_blank" title="Creative Commons Attribution 2.5 China Mainland License" href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。
                        如您有任何疑问或者授权方面的协商，请邮件联系我</a>。
                    </div>
                    <div class="col-md-6">
                      <p class="text-success hidden-print"><i class="fa fa-external-link"></i> <a href="/2015/04/17/spark-mllib-collaborative-filtering.html">Spark MLlib中的协同过滤</a></p>
                    </div>
                    <div class="col-md-6">
                       <p class="meta hidden-print pull-right">
                        
                            <i class="fa fa-folder-open"></i>
                            
                            <a class="btn btn-default btn-sm" href="/categories.html#spark">spark</a>
                          
                        
                        
                            <i class="fa fa-tags"></i>
                            
                            <a class="btn btn-default btn-sm" href="/tags.html#spark">spark</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#mllib">mllib</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#recommendation">recommendation</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#als">als</a>
                          
                        </p>
                    </div>
               </div><!--#post-text-->
          </div><!--#post-->
      </div> <!--#content-->

      <div id="post-comment" class="hidden-print">
      
<div id="comments">
  <div class="ds-thread" data-thread-key="/2015/04/17/spark-mllib-collaborative-filtering.html" data-url="http://blog.javachen.com/2015/04/17/spark-mllib-collaborative-filtering.html" data-title="Spark MLlib中的协同过滤"></div>
</div>



      </div>


          </div>
          <a href="#" class="btn back-to-top btn-dark btn-fixed-bottom hidden-print"><i class="fa fa-chevron-up"></i></a>
      </div>
      <div id="footer">
          <div class="container hidden-print">
              <p class="text-center"><i class="fa fa-copyright"></i> 2015 JavaChen Blog. Theme designed by <a href="/about.html" target="_blank" title="">yuke</a> with <a href="https://github.com/mojombo/jekyll/">Jekyll</a>, <a href="http://twitter.github.com/bootstrap/">Bootstrap</a> and <a href="http://fortawesome.github.com/Font-Awesome/">Font Awesome</a>.
  	            
            <script type="text/javascript">
                var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
                document.write(unescape("%3Cspan id='cnzz_stat_icon_1256628929'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1256628929' type='text/javascript'%3E%3C/script%3E"));</script>
            
            
    </p>
          </div>
      </div>

      <script type="text/javascript" src="/static/contrib/jquery/jquery.min.js"></script>
      <script type="text/javascript" src="/static/contrib/bootstrap/js/bootstrap.min.js"></script>
      <script type="text/javascript" src="/static/contrib/qrcode/jquery.qrcode.min.js"></script>
      <script type="text/javascript" src="/static/contrib/showup/showup.js"></script>
      <script type="text/javascript" src="/static/js/core.js"></script>
      
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"javachen"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
      

      <script type="text/javascript">
      $('#qr').qrcode({
          width: 128,
          height: 128,
          text: 'http://blog.javachen.com/2015/04/17/spark-mllib-collaborative-filtering.html'
      });
      </script>
  </body>
</html>
