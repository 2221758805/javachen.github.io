<!DOCTYPE html>
<html lang="zh-cn">
        <head>
      <meta charset="utf-8"/>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
      <title>Spark本地模式运行 - JavaChen Blog</title>
      <meta name="author" content="yuke"/>
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
      <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
      <link rel="canonical" href="http://blog.javachen.com/2015/03/30/spark-test-in-local-mode.html" />

      <link rel="stylesheet" href="/static/contrib/bootstrap/css/bootstrap.min.css" media="all" />
      <link rel="stylesheet" href="/static/css/style.css" media="all" />
      <link rel="stylesheet" href="/static/css/pygments.css" media="all" />
      <link rel="stylesheet" href="/static/contrib/font-awesome/css/font-awesome.min.css" media="all" />
      <link rel="stylesheet" type="text/css" href="/static/contrib/showup/showup.css" />

      <!-- atom & rss feed -->
      <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="JavaChen Blog RSS Feed" />
      <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="JavaChen Blog ATOM Feed" />

        <!-- fav and touch icons  -->
        <!-- Update these with your own images
        <link rel="shortcut icon" href="images/favicon.ico">
        <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
        <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
        -->

      <meta name="renderer" content="webkit|ie-stand">
      <meta name="baidu-site-verification" content="3HAhaWRiyR" />
      <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
      <meta name="sogou_site_verification" content="ofwXWFdthV"/>
      <meta property="wb:webmaster" content="b6081b2b8ab84c60" />
    </head>

    <body>
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">JavaChen Blog</a>
        </div>
        <div class="navbar-collapse collapse">
            <form id="search-form" class="form-group navbar-form navbar-right" role="search">
                  <div class="form-group">
                    <input type="text" name="q" value=""  id="query" class="form-control" placeholder="搜索" required autocomplete="off" ></input>
                    <input type="submit" class="btn btn-default" value=" Go" ></input>
                  </div>
              </form>
            <ul class="nav navbar-nav">
              <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
              <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
              <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
              <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
              
              <li><a href="https://github.com/javachen" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
              
              
              
              <li><a href="https://twitter.com/java_chen" target="_blank" title="twitter"><span class="fa fa-twitter fa-2x"></span></a></li>
              
              
              
              <li><a href="http://weibo.com/chenzhijun" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
              
              <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
            </ul>
        </div>

        </div><!--/.nav-collapse -->
      </div>
</div>

      <div id="wrap">
          <div class="container">
                 <div id="content">
          <ul class="pager hidden-print">
               
                <li class="previous"><a href="/2015/03/30/reading-list-2015-03.html" title="Reading List 2015-03"><i class="fa fa-angle-double-left"></i>&nbsp;Reading List 2015-03</a></li>
                
                
                <li class="next"><a href="/2015/04/03/spark-sql-datasource.html" title="Spark SQL中的数据源">Spark SQL中的数据源&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
                
          </ul>

           <div id="post" class="clearfix">
              <div id="post-title" class="page-header text-center">
                  <h1> Spark本地模式运行  </h1>
              </div>
              <p class="text-muted clearfix">
                  <span class="pull-right">2015.03.30 | <a href="#comments">Comments</a></span>
              </p>
              <div id="qr" class="qrcode visible-lg"></div>

              <div id="post-text">
                    <p>Spark的安装分为几种模式，其中一种是本地运行模式，只需要在单节点上解压即可运行，这种模式不需要依赖Hadoop 环境。在本地运行模式中，master和worker都运行在一个jvm进程中，通过该模式，可以快速的测试Spark的功能。</p>

<h1 id="下载-spark">下载 Spark</h1>

<p>下载地址为<a href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a>，根据页面提示选择一个合适的版本下载，这里我下载的是 <a href="http://mirror.bit.edu.cn/apache/spark/spark-1.3.0/spark-1.3.0-bin-cdh4.tgz">spark-1.3.0-bin-cdh4.tgz</a>。下载之后解压：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"> <span class="nb">cd</span> ~
 wget http://mirror.bit.edu.cn/apache/spark/spark-1.3.0/spark-1.3.0-bin-cdh4.tgz
 tar -xf spark-1.3.0-bin-cdh4.tgz
 <span class="nb">cd </span>spark-1.3.0-bin-cdh4
</code></pre></div>
<p>下载之后的目录为：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">⇒  tree -L 1
.
├── CHANGES.txt
├── LICENSE
├── NOTICE
├── README.md
├── RELEASE
├── bin
├── conf
├── data
├── ec2
├── examples
├── lib
├── python
└── sbin
</code></pre></div>
<h1 id="运行-spark-shell">运行 spark-shell</h1>

<p>本地模式运行spark-shell非常简单，只要运行以下命令即可，假设当前目录是$SPARK_HOME</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ MASTER</span><span class="o">=</span><span class="nb">local</span> 
<span class="nv">$ </span>bin/spark-shell
</code></pre></div>
<p><code class="prettyprint">MASTER=local</code>就是表明当前运行在单机模式。如果一切顺利，将看到下面的提示信息：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Created spark context..
Spark context available as sc.
</code></pre></div>
<p>这表明spark-shell中已经内置了Spark context的变量，名称为sc，我们可以直接使用该变量进行后续的操作。</p>

<p>spark-shell 后面设置 master 参数，可以支持更多的模式，请参考 <a href="http://spark.apache.org/docs/latest/submitting-applications.html#master-urls">http://spark.apache.org/docs/latest/submitting-applications.html#master-urls</a>。</p>

<p>我们在sparkshell中运行一下最简单的例子，统计在README.md中含有Spark的行数有多少，在spark-shell中输入如下代码：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">scala&gt;sc.textFile<span class="o">(</span><span class="s2">&quot;README.md&quot;</span><span class="o">)</span>.filter<span class="o">(</span>_.contains<span class="o">(</span><span class="s2">&quot;Spark&quot;</span><span class="o">))</span>.count
</code></pre></div>
<p>如果你觉得输出的日志太多，你可以从模板文件创建  conf/log4j.properties ：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>mv conf/log4j.properties.template conf/log4j.properties
</code></pre></div>
<p>然后修改日志输出级别为<code class="prettyprint">WARN</code>：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">log4j.rootCategory=WARN, console
</code></pre></div>
<p>如果你设置的 log4j 日志等级为 INFO，则你可以看到这样的一行日志 <code class="prettyprint">INFO SparkUI: Started SparkUI at http://10.9.4.165:4040</code>，意思是 Spark 启动了一个 web 服务器，你可以通过浏览器访问<a href="http://10.9.4.165:4040">http://10.9.4.165:4040</a>来查看 Spark 的任务运行状态等信息。</p>

<h1 id="pyspark">pyspark</h1>

<p>运行 bin/pyspark 的输出为：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">$ bin/pyspark
Python 2.7.6 (default, Sep  9 2014, 15:04:36)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.39)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
Spark assembly has been built with Hive, including Datanucleus jars on classpath
Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8
15/03/30 15:19:07 WARN Utils: Your hostname, june-mac resolves to a loopback address: 127.0.0.1; using 10.9.4.165 instead (on interface utun0)
15/03/30 15:19:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
15/03/30 15:19:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ / __/  _/
   /__ / .__/\_,_/_/ /_/\_\   version 1.3.0
      /_/

Using Python version 2.7.6 (default, Sep  9 2014 15:04:36)
SparkContext available as sc, HiveContext available as sqlCtx.
</code></pre></div>
<p>你也可以使用 IPython 来运行 Spark：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">IPYTHON=1  ./bin/pyspark
</code></pre></div>
<p>如果要使用 IPython NoteBook，则运行：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">IPYTHON_OPTS=&quot;notebook&quot;  ./bin/pyspark
</code></pre></div>
<p>从日志可以看到，不管是 bin/pyspark 还是 bin/spark-shell，他们都有两个内置的变量：sc 和 sqlCtx。</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nc">SparkContext</span> <span class="n">available</span> <span class="n">as</span> <span class="n">sc</span><span class="o">,</span> <span class="nc">HiveContext</span> <span class="n">available</span> <span class="n">as</span> <span class="n">sqlCtx</span>
</code></pre></div>
<p>sc 代表着 Spark 的上下文，通过该变量可以执行 Spark 的一些操作，而 sqlCtx 代表着 HiveContext 的上下文。</p>

<h1 id="spark-submit">spark-submit</h1>

<p>在Spark1.0之后提供了一个统一的脚本spark-submit来提交任务。</p>

<p>对于 python 程序，我们可以直接使用 spark-submit：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>mkdir -p /usr/lib/spark/examples/python
<span class="nv">$ </span>tar zxvf /usr/lib/spark/lib/python.tar.gz -C /usr/lib/spark/examples/python

<span class="nv">$ </span>./bin/spark-submit examples/python/pi.py 10
</code></pre></div>
<p>对于 Java 程序，我们需要先编译代码然后打包运行：</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>spark-submit --class <span class="s2">&quot;SimpleApp&quot;</span> --master <span class="nb">local</span><span class="o">[</span>4<span class="o">]</span> simple-project-1.0.jar
</code></pre></div>
<h1 id="测试-rdd">测试 RDD</h1>

<p>在 Spark 中，我们操作的集合被称为 RDD，他们被并行拷贝到集群各个节点上。我们可以通过 sc 来创建 RDD 。</p>

<p>创建 RDD 有两种方式：</p>

<ul>
<li><code class="prettyprint">sc.parallelize()</code></li>
<li><code class="prettyprint">sc.textFile()</code></li>
</ul>

<p>使用 Scala 对 RDD 的一些操作：</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">rdd1</span><span class="k">=</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">List</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">3</span><span class="o">))</span>
<span class="k">val</span> <span class="n">rdd2</span><span class="k">=</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">List</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">))</span>

<span class="c1">//转换操作</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="mi">2</span><span class="o">*).</span><span class="n">collect</span> <span class="c1">//等同于：rdd1.map(t=&gt;2*t).collect</span>
<span class="c1">//Array[Int] = Array(2, 4, 6, 6)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span><span class="o">&gt;</span><span class="mi">2</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[Int] = Array(3, 3)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">_</span> <span class="n">to</span> <span class="mi">4</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[Int] = Array(1, 2, 3, 4, 2, 3, 4, 3, 4, 3, 4)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">sample</span><span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[Int] = Array(3, 3)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">sample</span><span class="o">(</span><span class="kc">true</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[Int] = Array(3)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">union</span><span class="o">(</span><span class="n">rdd2</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[Int] = Array(1, 2, 3, 3, 3, 4, 5)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">distinct</span><span class="o">().</span><span class="n">collect</span>
<span class="c1">//Array[Int] = Array(1, 2, 3)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">)).</span><span class="n">groupByKey</span><span class="o">.</span><span class="n">collect</span>
<span class="c1">//Array[(Int, Iterable[Int])] = Array((1,CompactBuffer(1)), (2,CompactBuffer(2)), (3,CompactBuffer(3, 3)))</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">)).</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[(Int, Int)] = Array((1,1), (2,2), (3,6))</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">)).</span><span class="n">sortByKey</span><span class="o">(</span><span class="kc">false</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[(Int, Int)] = Array((3,3), (3,3), (2,2), (1,1))</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">)).</span><span class="n">join</span><span class="o">(</span><span class="n">rdd2</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">))).</span><span class="n">collect</span>
<span class="c1">//Array[(Int, (Int, Int))] = Array((3,(3,3)), (3,(3,3)))</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">)).</span><span class="n">cogroup</span><span class="o">(</span><span class="n">rdd2</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">))).</span><span class="n">collect</span>
<span class="c1">//Array[(Int, (Iterable[Int], Iterable[Int]))] = Array((4,(CompactBuffer(),CompactBuffer(4))), (1,(CompactBuffer(1),CompactBuffer())), (5,(CompactBuffer(),CompactBuffer(5))), (2,(CompactBuffer(2),CompactBuffer())), (3,(CompactBuffer(3, 3),CompactBuffer(3))))</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">cartesian</span><span class="o">(</span><span class="n">rdd2</span><span class="o">).</span><span class="n">collect</span><span class="o">()</span>
<span class="c1">//Array[(Int, Int)] = Array((1,3), (1,4), (1,5), (2,3), (2,4), (2,5), (3,3), (3,4), (3,5), (3,3), (3,4), (3,5))</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">pipe</span><span class="o">(</span><span class="s">&quot;head -n 1&quot;</span><span class="o">).</span><span class="n">collect</span>
<span class="c1">//Array[String] = Array(1, 2, 3, 3)</span>

<span class="c1">//动作操作</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">)</span>
<span class="c1">//Int = 9</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">collect</span>
<span class="c1">//Array[Int] = Array(1, 2, 3, 3)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
<span class="c1">//Int = 1</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="c1">//Array[Int] = Array(1, 2)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">top</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="c1">//Array[Int] = Array(3, 3)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">takeOrdered</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="c1">//Array[Int] = Array(1, 2)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span><span class="o">=&gt;(</span><span class="n">i</span><span class="o">,</span><span class="n">i</span><span class="o">)).</span><span class="n">countByKey</span><span class="o">()</span>
<span class="c1">//scala.collection.Map[Int,Long] = Map(1 -&gt; 1, 2 -&gt; 1, 3 -&gt; 2)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">countByValue</span><span class="o">()</span>
<span class="c1">//scala.collection.Map[Int,Long] = Map(1 -&gt; 1, 2 -&gt; 1, 3 -&gt; 2)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">intersection</span><span class="o">(</span><span class="n">rdd2</span><span class="o">).</span><span class="n">collect</span><span class="o">()</span>
<span class="c1">//Array[Int] = Array(3)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">subtract</span><span class="o">(</span><span class="n">rdd2</span><span class="o">).</span><span class="n">collect</span><span class="o">()</span>
<span class="c1">//Array[Int] = Array(1, 2)</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="c1">//3</span>
<span class="c1">//2</span>
<span class="c1">//3</span>
<span class="c1">//1</span>

<span class="n">rdd1</span><span class="o">.</span><span class="n">foreachPartition</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">println</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">)))</span>
</code></pre></div>
<p>更多例子，参考<a href="http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html">http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html</a>。</p>

                    <br/>
                    <div class="well">
                        原创文章，转载请注明： 转载自<a href="http://blog.javachen.com">JavaChen Blog</a>，作者：<a href="http://blog.javachen.com/about.html">yuke</a><br/>
                        本文链接地址：<a href="/2015/03/30/spark-test-in-local-mode.html">http://blog.javachen.com/2015/03/30/spark-test-in-local-mode.html</a><br/>
                        本文基于<a target="_blank" title="Creative Commons Attribution 2.5 China Mainland License" href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。
                        如您有任何疑问或者授权方面的协商，请邮件联系我</a>。
                    </div>
                    <div class="col-md-6">
                      <p class="text-success hidden-print"><i class="fa fa-external-link"></i> <a href="/2015/03/30/spark-test-in-local-mode.html">Spark本地模式运行</a></p>
                    </div>
                    <div class="col-md-6">
                       <p class="meta hidden-print pull-right">
                        
                            <i class="fa fa-folder-open"></i>
                            
                            <a class="btn btn-default btn-sm" href="/categories.html#spark">spark</a>
                          
                        
                        
                            <i class="fa fa-tags"></i>
                            
                            <a class="btn btn-default btn-sm" href="/tags.html#spark">spark</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#scala">scala</a>
                          
                        </p>
                    </div>
               </div><!--#post-text-->
          </div><!--#post-->
      </div> <!--#content-->

      <div id="post-comment" class="hidden-print">
      
<div id="comments">
  <div class="ds-thread" data-thread-key="/2015/03/30/spark-test-in-local-mode.html" data-url="http://blog.javachen.com/2015/03/30/spark-test-in-local-mode.html" data-title="Spark本地模式运行"></div>
</div>



      </div>


          </div>
          <a href="#" class="btn back-to-top btn-dark btn-fixed-bottom hidden-print"><i class="fa fa-chevron-up"></i></a>
      </div>
      <div id="footer">
          <div class="container hidden-print">
              <p class="text-center"><i class="fa fa-copyright"></i> 2015 JavaChen Blog. Theme designed by <a href="/about.html" target="_blank" title="">yuke</a> with <a href="https://github.com/mojombo/jekyll/">Jekyll</a>, <a href="http://twitter.github.com/bootstrap/">Bootstrap</a> and <a href="http://fortawesome.github.com/Font-Awesome/">Font Awesome</a>.
  	            
            <script type="text/javascript">
                var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
                document.write(unescape("%3Cspan id='cnzz_stat_icon_1256628929'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1256628929' type='text/javascript'%3E%3C/script%3E"));</script>
            
            
    </p>
          </div>
      </div>

      <script type="text/javascript" src="/static/contrib/jquery/jquery.min.js"></script>
      <script type="text/javascript" src="/static/contrib/bootstrap/js/bootstrap.min.js"></script>
      <script type="text/javascript" src="/static/contrib/qrcode/jquery.qrcode.min.js"></script>
      <script type="text/javascript" src="/static/contrib/showup/showup.js"></script>
      <script type="text/javascript" src="/static/js/core.js"></script>
      
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"javachen"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
      

      <script type="text/javascript">
      $('#qr').qrcode({
          width: 128,
          height: 128,
          text: 'http://blog.javachen.com/2015/03/30/spark-test-in-local-mode.html'
      });
      </script>
  </body>
</html>
