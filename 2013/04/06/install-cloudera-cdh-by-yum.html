<!DOCTYPE html>
<html lang="zh-cn">
        <head>
      <meta charset="utf-8"/>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
      <title>使用yum源安装CDH Hadoop集群 - JavaChen Blog</title>
      <meta name="author" content="yuke"/>
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
      <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
      <link rel="canonical" href="http://blog.javachen.com/2013/04/06/install-cloudera-cdh-by-yum.html" />

      <link rel="stylesheet" href="/static/contrib/bootstrap/css/bootstrap.min.css" media="all" />
      <link rel="stylesheet" href="/static/css/style.css" media="all" />
      <link rel="stylesheet" href="/static/css/pygments.css" media="all" />
      <link rel="stylesheet" href="/static/contrib/font-awesome/css/font-awesome.min.css" media="all" />
      <link rel="stylesheet" type="text/css" href="/static/contrib/showup/showup.css" />

      <!-- atom & rss feed -->
      <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="JavaChen Blog RSS Feed" />
      <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="JavaChen Blog ATOM Feed" />

        <!-- fav and touch icons  -->
        <!-- Update these with your own images
        <link rel="shortcut icon" href="images/favicon.ico">
        <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
        <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
        -->

      <meta name="renderer" content="webkit|ie-stand">
      <meta name="baidu-site-verification" content="3HAhaWRiyR" />
      <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
      <meta name="sogou_site_verification" content="ofwXWFdthV"/>
      <meta property="wb:webmaster" content="b6081b2b8ab84c60" />
    </head>

    <body>
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">JavaChen Blog</a>
        </div>
        <div class="navbar-collapse collapse">
            <form id="search-form" class="form-group navbar-form navbar-right" role="search">
                  <div class="form-group">
                    <input type="text" name="q" value=""  id="query" class="form-control" placeholder="搜索" required autocomplete="off" ></input>
                    <input type="submit" class="btn btn-default" value=" Go" ></input>
                  </div>
              </form>
            <ul class="nav navbar-nav">
              <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
              <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
              <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
              <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
              
              <li><a href="https://github.com/javachen" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
              
              
              
              <li><a href="https://twitter.com/java_chen" target="_blank" title="twitter"><span class="fa fa-twitter fa-2x"></span></a></li>
              
              
              
              <li><a href="http://weibo.com/chenzhijun" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
              
              <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
            </ul>
        </div>

        </div><!--/.nav-collapse -->
      </div>
</div>

      <div id="wrap">
          <div class="container">
                 <div id="content">
          <ul class="pager hidden-print">
               
                <li class="previous"><a href="/2013/03/29/install-impala.html" title="安装Impala过程"><i class="fa fa-angle-double-left"></i>&nbsp;安装Impala过程</a></li>
                
                
                <li class="next"><a href="/2013/04/07/add-a-field-from-paramter-to-output.html" title="Kettle中添加一个参数字段到输出">Kettle中添加一个参数字段到输出&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
                
          </ul>

           <div id="post" class="clearfix">
              <div id="post-title" class="page-header text-center">
                  <h1> 使用yum源安装CDH Hadoop集群  </h1>
              </div>
              <p class="text-muted clearfix">
                  <span class="pull-right">2013.04.06 | <a href="#comments">Comments</a></span>
              </p>
              <div id="qr" class="qrcode visible-lg"></div>

              <div id="post-text">
                    <p>本文主要是记录使用yum安装CDH Hadoop集群的过程，包括HDFS、Yarn、Hive和HBase。<code>本文使用CDH5.4版本进行安装，故下文中的过程都是针对CDH5.4版本的</code>。</p>

<h1 id="section">0. 环境说明</h1>

<p>系统环境：</p>

<ul>
  <li>操作系统：CentOs 6.6</li>
  <li>Hadoop版本：<code>CDH5.4</code></li>
  <li>JDK版本：<code>1.7.0_71</code></li>
  <li>运行用户：root</li>
</ul>

<p>集群各节点角色规划为：</p>

<pre><code>192.168.56.121        cdh1     NameNode、ResourceManager、HBase、Hive metastore、Impala Catalog、Impala statestore、Sentry 
192.168.56.122        cdh2     DataNode、SecondaryNameNode、NodeManager、HBase、Hive Server2、Impala Server
192.168.56.123        cdh3     DataNode、HBase、NodeManager、Hive Server2、Impala Server
</code></pre>

<p>cdh1作为master节点，其他节点作为slave节点。</p>

<h1 id="section-1">1. 准备工作</h1>

<p>安装 Hadoop 集群前先做好下面的准备工作，在修改配置文件的时候，建议在一个节点上修改，然后同步到其他节点，例如：对于 hdfs 和 yarn ，在 NameNode 节点上修改然后再同步，对于 HBase，选择一个节点再同步。因为要同步配置文件和在多个节点启动服务，建议配置 ssh 无密码登陆。</p>

<h2 id="hosts">1.1 配置hosts</h2>

<p>CDH 要求使用 IPv4，IPv6 不支持，<strong>禁用IPv6方法：</strong></p>

<pre><code class="language-bash">$ vim /etc/sysctl.conf
#disable ipv6
net.ipv6.conf.all.disable_ipv6=1
net.ipv6.conf.default.disable_ipv6=1
net.ipv6.conf.lo.disable_ipv6=1
</code></pre>

<p>使其生效：</p>

<pre><code class="language-bash">$ sysctl -p
</code></pre>

<p>最后确认是否已禁用：</p>

<pre><code class="language-bash">$ cat /proc/sys/net/ipv6/conf/all/disable_ipv6
1
</code></pre>

<p>1、设置hostname，以cdh1为例：</p>

<pre><code class="language-bash">$ hostname cdh1
</code></pre>

<p>2、确保<code>/etc/hosts</code>中包含ip和FQDN，如果你在使用DNS，保存这些信息到<code>/etc/hosts</code>不是必要的，却是最佳实践。</p>

<p>3、确保<code>/etc/sysconfig/network</code>中包含<code>hostname=cdh1</code></p>

<p>4、检查网络，运行下面命令检查是否配置了hostname以及其对应的ip是否正确。</p>

<p>运行<code>uname -a</code>查看hostname是否匹配<code>hostname</code>命令运行的结果：</p>

<pre><code class="language-bash">$ uname -a
Linux cdh1 2.6.32-358.23.2.el6.x86_64 #1 SMP Wed Oct 16 18:37:12 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
$ hostname
cdh1
</code></pre>

<p>运行<code>/sbin/ifconfig</code>查看ip:</p>

<pre><code class="language-bash">$ ifconfig
eth1      Link encap:Ethernet  HWaddr 08:00:27:75:E0:95  
          inet addr:192.168.56.121  Bcast:192.168.56.255  Mask:255.255.255.0
......
</code></pre>

<p>先安装bind-utils，才能运行host命令：</p>

<pre><code class="language-bash">$ yum install bind-utils -y
</code></pre>

<p>运行下面命令查看hostname和ip是否匹配:</p>

<pre><code class="language-bash">$ host -v -t A `hostname`
Trying "cdh1"
...
;; ANSWER SECTION:
cdh1. 60 IN	A	192.168.56.121
</code></pre>

<p>5、hadoop的所有配置文件中配置节点名称时，请使用hostname和不是ip</p>

<h2 id="section-2">1.2 关闭防火墙</h2>

<pre><code class="language-bash">$ setenforce 0
$ vim /etc/sysconfig/selinux #修改SELINUX=disabled

#清空iptables
$ iptables -F
</code></pre>

<h2 id="section-3">1.3 时钟同步</h2>

<h2 id="section-4">搭建时钟同步服务器</h2>

<p>这里选择 cdh1 节点为时钟同步服务器，其他节点为客户端同步时间到该节点。安装ntp:</p>

<pre><code class="language-bash">$ yum install ntp
</code></pre>

<p>修改 cdh1 上的配置文件 <code>/etc/ntp.conf</code> :</p>

<pre><code>restrict default ignore   //默认不允许修改或者查询ntp,并且不接收特殊封包
restrict 127.0.0.1        //给于本机所有权限
restrict 192.168.56.0 mask 255.255.255.0 notrap nomodify  //给于局域网机的机器有同步时间的权限
server  192.168.56.121     # local clock
driftfile /var/lib/ntp/drift
fudge   127.127.1.0 stratum 10
</code></pre>

<p>启动 ntp：</p>

<pre><code class="language-bash">#设置开机启动
$ chkconfig ntpd on

$ service ntpd start
</code></pre>

<p>ntpq用来监视ntpd操作，使用标准的NTP模式6控制消息模式，并与NTP服务器通信。</p>

<p><code>ntpq -p</code> 查询网络中的NTP服务器，同时显示客户端和每个服务器的关系。</p>

<pre><code>$ ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
*LOCAL(1)        .LOCL.           5 l    6   64    1    0.000    0.000   0.000
</code></pre>

<ul>
  <li>”* “：响应的NTP服务器和最精确的服务器。</li>
  <li>”+”：响应这个查询请求的NTP服务器。</li>
  <li>“blank（空格）”：没有响应的NTP服务器。</li>
  <li>“remote” ：响应这个请求的NTP服务器的名称。</li>
  <li>“refid “：NTP服务器使用的更高一级服务器的名称。</li>
  <li>“st”：正在响应请求的NTP服务器的级别。</li>
  <li>“when”：上一次成功请求之后到现在的秒数。</li>
  <li>“poll”：当前的请求的时钟间隔的秒数。</li>
  <li>“offset”：主机通过NTP时钟同步与所同步时间源的时间偏移量，单位为毫秒（ms）。</li>
</ul>

<h2 id="section-5">客户端的配置</h2>

<p>在cdh2和cdh3节点上执行下面操作：</p>

<pre><code class="language-bash">$ ntpdate cdh1
</code></pre>

<p>Ntpd启动的时候通常需要一段时间大概5分钟进行时间同步，所以在ntpd刚刚启动的时候还不能正常提供时钟服务，报错”no server suitable for synchronization found”。启动时候需要等待5分钟。</p>

<p>如果想定时进行时间校准，可以使用crond服务来定时执行。</p>

<pre><code class="language-bash"># 每天 1:00 Linux 系统就会自动的进行网络时间校准
00 1 * * * root /usr/sbin/ntpdate 192.168.56.121 &gt;&gt; /root/ntpdate.log 2&gt;&amp;1
</code></pre>

<h2 id="jdk">1.4 安装jdk</h2>

<p>CDH5.4要求使用JDK1.7，JDK的安装过程请参考网上文章。</p>

<h2 id="yum">1.5 设置本地yum源</h2>

<p>CDH官方的yum源地址在 http://archive.cloudera.com/cdh4/redhat/6/x86_64/cdh/cloudera-cdh4.repo 或 http://archive.cloudera.com/cdh5/redhat/6/x86_64/cdh/cloudera-cdh5.repo ，请根据你安装的cdh版本修改该文件中baseurl的路径。</p>

<p>你可以从<a href="http://archive.cloudera.com/cdh4/repo-as-tarball/">这里</a>下载 cdh4 的仓库压缩包，或者从<a href="http://archive.cloudera.com/cdh5/repo-as-tarball/">这里</a> 下载 cdh5 的仓库压缩包。</p>

<p>因为我是使用的centos操作系统，故我这里下载的是cdh5的centos6压缩包，将其下载之后解压到ftp服务的路径下，然后配置cdh的本地yum源：</p>

<pre><code>[hadoop]
name=hadoop
baseurl=ftp://cdh1/cdh/5/
enabled=1
gpgcheck=0
</code></pre>

<p>操作系统的yum源，建议你通过下载 centos 的 dvd 然后配置一个本地的 yum 源。</p>

<h1 id="hdfs">2. 安装和配置HDFS</h1>

<p>根据文章开头的节点规划，cdh1 为NameNode节点，cdh2为SecondaryNameNode节点，cdh2 和 cdh3 为DataNode节点</p>

<p>在 cdh1 节点安装 hadoop-hdfs-namenode：</p>

<pre><code class="language-bash">$ yum install hadoop hadoop-hdfs hadoop-client hadoop-doc hadoop-debuginfo hadoop-hdfs-namenode
</code></pre>

<p>在 cdh2 节点安装 hadoop-hdfs-secondarynamenode</p>

<pre><code class="language-bash">$ yum install hadoop-hdfs-secondarynamenode -y
</code></pre>

<p>在 cdh2、cdh3节点安装 hadoop-hdfs-datanode</p>

<pre><code class="language-bash">$ yum install hadoop hadoop-hdfs hadoop-client hadoop-doc hadoop-debuginfo hadoop-hdfs-datanode -y
</code></pre>

<p>NameNode HA 的配置过程请参考<a href="/2014/07/18/install-hdfs-ha-in-cdh.html">CDH中配置HDFS HA</a>，建议暂时不用配置。</p>

<h2 id="hadoop">2.1 修改hadoop配置文件</h2>

<p>在<code>/etc/hadoop/conf/core-site.xml</code>中设置<code>fs.defaultFS</code>属性值，该属性指定NameNode是哪一个节点以及使用的文件系统是file还是hdfs，格式：<code>hdfs://&lt;namenode host&gt;:&lt;namenode port&gt;/</code>，默认的文件系统是<code>file:///</code>：</p>

<pre><code class="language-xml">&lt;property&gt;
 &lt;name&gt;fs.defaultFS&lt;/name&gt;
 &lt;value&gt;hdfs://cdh1:8020&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>在<code>/etc/hadoop/conf/hdfs-site.xml</code>中设置<code>dfs.permissions.superusergroup</code>属性，该属性指定hdfs的超级用户，默认为hdfs，你可以修改为hadoop：</p>

<pre><code class="language-xml">&lt;property&gt;
 &lt;name&gt;dfs.permissions.superusergroup&lt;/name&gt;
 &lt;value&gt;hadoop&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<blockquote>
  <p>更多的配置信息说明，请参考 <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html">Apache Cluster Setup</a></p>
</blockquote>

<h2 id="section-6">2.2 指定本地文件目录</h2>

<p>在hadoop中默认的文件路径以及权限要求如下：</p>

<pre><code>目录									所有者		权限		默认路径
hadoop.tmp.dir						hdfs:hdfs	drwx------	/var/hadoop
dfs.namenode.name.dir				hdfs:hdfs	drwx------	file://${hadoop.tmp.dir}/dfs/name
dfs.datanode.data.dir				hdfs:hdfs	drwx------	file://${hadoop.tmp.dir}/dfs/data
dfs.namenode.checkpoint.dir			hdfs:hdfs	drwx------	file://${hadoop.tmp.dir}/dfs/namesecondary
</code></pre>

<p>说明你可以在 hdfs-site.xm l中只配置<code>hadoop.tmp.dir</code>，也可以分别配置上面的路径。这里使用分别配置的方式，hdfs-site.xml中配置如下：</p>

<pre><code class="language-xml">&lt;property&gt;
 &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
 &lt;value&gt;file:///data/dfs/nn&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
 &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
&lt;value&gt;file:///data/dfs/dn&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>在<strong>NameNode</strong>上手动创建 <code>dfs.name.dir</code> 或 <code>dfs.namenode.name.dir</code> 的本地目录：</p>

<pre><code class="language-bash">$ mkdir -p /data/dfs/nn
</code></pre>

<p>在<strong>DataNode</strong>上手动创建 <code>dfs.data.dir</code> 或 <code>dfs.datanode.data.dir</code> 的本地目录：</p>

<pre><code class="language-bash">$ mkdir -p /data/dfs/dn
</code></pre>

<p>修改上面目录所有者：</p>

<pre><code>$ chown -R hdfs:hdfs /data/dfs/nn /data/dfs/dn
</code></pre>

<p>hadoop的进程会自动设置 <code>dfs.data.dir</code> 或 <code>dfs.datanode.data.dir</code>，但是 <code>dfs.name.dir</code> 或 <code>dfs.namenode.name.dir</code> 的权限默认为755，需要手动设置为700：</p>

<pre><code class="language-bash">$ chmod 700 /data/dfs/nn

# 或者
$ chmod go-rx /data/dfs/nn
</code></pre>

<p>注意：DataNode的本地目录可以设置多个，你可以设置 <code>dfs.datanode.failed.volumes.tolerated</code> 参数的值，表示能够容忍不超过该个数的目录失败。</p>

<h2 id="secondarynamenode">2.3 配置 SecondaryNameNode</h2>

<p>配置 SecondaryNameNode 需要在 <code>/etc/hadoop/conf/hdfs-site.xml</code> 中添加以下参数：</p>

<pre><code class="language-bash">dfs.namenode.checkpoint.check.period
dfs.namenode.checkpoint.txns
dfs.namenode.checkpoint.dir
dfs.namenode.checkpoint.edits.dir
dfs.namenode.num.checkpoints.retained
</code></pre>

<p>在 <code>/etc/hadoop/conf/hdfs-site.xml</code> 中加入如下配置，将cdh2设置为 SecondaryNameNode：</p>

<pre><code class="language-xml">&lt;property&gt;
  &lt;name&gt;dfs.secondary.http.address&lt;/name&gt;
  &lt;value&gt;cdh2:50090&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>设置多个secondarynamenode，请参考<a href="http://blog.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/">multi-host-secondarynamenode-configuration</a>.</p>

<h2 id="section-7">2.4 开启回收站功能</h2>

<p>回收站功能默认是关闭的，建议打开。在 <code>/etc/hadoop/conf/core-site.xml</code> 中添加如下两个参数：</p>

<ul>
  <li><code>fs.trash.interval</code>,该参数值为时间间隔，单位为分钟，默认为0，表示回收站功能关闭。该值表示回收站中文件保存多长时间，如果服务端配置了该参数，则忽略客户端的配置；如果服务端关闭了该参数，则检查客户端是否有配置该参数；</li>
  <li><code>fs.trash.checkpoint.interval</code>，该参数值为时间间隔，单位为分钟，默认为0。该值表示检查回收站时间间隔，该值要小于<code>fs.trash.interval</code>，该值在服务端配置。如果该值设置为0，则使用 <code>fs.trash.interval</code> 的值。</li>
</ul>

<h2 id="datanode">2.5 (可选)配置DataNode存储的负载均衡</h2>

<p>在 <code>/etc/hadoop/conf/hdfs-site.xml</code> 中配置以下三个参数：</p>

<ul>
  <li><code>dfs.datanode.fsdataset. volume.choosing.policy</code></li>
  <li><code>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold</code></li>
  <li><code>dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction</code></li>
</ul>

<p>详细说明，请参考 <a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/cdh5ig_hdfs_cluster_deploy.html#concept_ncq_nnk_ck_unique_1">Optionally configure DataNode storage balancing</a>。</p>

<h2 id="webhdfs">2.6 开启WebHDFS</h2>

<p>在NameNode节点上安装：</p>

<pre><code class="language-bash">$ yum install hadoop-httpfs -y
</code></pre>

<p>然后修改 /etc/hadoop/conf/core-site.xml配置代理用户：</p>

<pre><code class="language-xml">&lt;property&gt;  
&lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt;  
&lt;value&gt;*&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
&lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt;  
&lt;value&gt;*&lt;/value&gt;  
&lt;/property&gt;
</code></pre>

<h2 id="lzo">2.7 配置LZO</h2>

<p>下载repo文件到 <code>/etc/yum.repos.d/</code>:</p>

<ul>
  <li>如果你安装的是 CDH4，请下载<a href="http://archive.cloudera.com/gplextras/redhat/6/x86_64/gplextras/cloudera-gplextras4.repo">Red Hat/CentOS 6</a></li>
  <li>如果你安装的是 CDH5，请下载<a href="http://archive.cloudera.com/gplextras5/redhat/6/x86_64/gplextras/cloudera-gplextras5.repo">Red Hat/CentOS 6</a></li>
</ul>

<p>然后，安装lzo:</p>

<pre><code class="language-bash">$ yum install hadoop-lzo* impala-lzo  -y
</code></pre>

<p>最后，在 <code>/etc/hadoop/conf/core-site.xml</code> 中添加如下配置：</p>

<pre><code class="language-xml">&lt;property&gt;
  &lt;name&gt;io.compression.codecs&lt;/name&gt;
  &lt;value&gt;org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,
org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,
com.hadoop.compression.lzo.LzopCodec&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;
  &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>更多关于LZO信息，请参考：<a href="http://wiki.apache.org/hadoop/UsingLzoCompression">Using LZO Compression</a></p>

<h2 id="snappy">2.8 (可选)配置Snappy</h2>

<p>cdh 的 rpm 源中默认已经包含了 snappy ，直接在每个节点安装Snappy：</p>

<pre><code class="language-bash">$ yum install snappy snappy-devel  -y
</code></pre>

<p>然后，在 <code>core-site.xml</code> 中修改<code>io.compression.codecs</code>的值，添加 <code>org.apache.hadoop.io.compress.SnappyCodec</code> 。</p>

<p>使 snappy 对 hadoop 可用：</p>

<pre><code class="language-bash">$ ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/
</code></pre>

<h2 id="hdfs-1">2.9 启动HDFS</h2>

<p>将cdh1上的配置文件同步到每一个节点：</p>

<pre><code class="language-bash">$ scp -r /etc/hadoop/conf root@cdh2:/etc/hadoop/
$ scp -r /etc/hadoop/conf root@cdh3:/etc/hadoop/
</code></pre>

<p>在cdh1节点格式化NameNode：</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop namenode -format
</code></pre>

<p>在每个节点运行下面命令启动hdfs：</p>

<pre><code class="language-bash">$ for x in `ls /etc/init.d/|grep  hadoop-hdfs` ; do service $x start ; done
</code></pre>

<p>在 hdfs 运行之后，创建 <code>/tmp</code> 临时目录，并设置权限为 <code>1777</code>：</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -mkdir /tmp
$ sudo -u hdfs hadoop fs -chmod -R 1777 /tmp
</code></pre>

<p>如果安装了HttpFS，则启动 HttpFS 服务：</p>

<pre><code class="language-bash">$ service hadoop-httpfs start
</code></pre>

<h2 id="section-8">2.10 测试</h2>

<p>通过 <a href="http://cdh1:50070/">http://cdh1:50070/</a> 可以访问 NameNode 页面。使用 curl 运行下面命令，可以测试 webhdfs 并查看执行结果：</p>

<pre><code class="language-bash">$ curl "http://localhost:14000/webhdfs/v1?op=gethomedirectory&amp;user.name=hdfs"
{"Path":"\/user\/hdfs"}
</code></pre>

<p>更多的 API，请参考 <a href="http://archive.cloudera.com/cdh5/cdh/5/hadoop/hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS REST API</a></p>

<h1 id="yarn">3. 安装和配置YARN</h1>

<p>根据文章开头的节点规划，cdh1 为resourcemanager节点，cdh2 和 cdh3 为nodemanager节点，为了简单，historyserver 也装在 cdh1 节点上。</p>

<h2 id="section-9">3.1 安装服务</h2>

<p>在 cdh1 节点安装:</p>

<pre><code class="language-bash">$ yum install hadoop-yarn hadoop-yarn-resourcemanager -y

#安装 historyserver
$ yum install hadoop-mapreduce-historyserver hadoop-yarn-proxyserver -y
</code></pre>

<p>在 cdh2、cdh3 节点安装:</p>

<pre><code class="language-bash">$ yum install hadoop-yarn hadoop-yarn-nodemanager hadoop-mapreduce -y
</code></pre>

<h2 id="section-10">3.2 修改配置参数</h2>

<p>要想使用YARN，需要在 <code>/etc/hadoop/conf/mapred-site.xml</code> 中做如下配置:</p>

<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
	&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>修改/etc/hadoop/conf/yarn-site.xml，配置resourcemanager的节点名称以及一些服务的端口号：</p>

<pre><code class="language-xml">&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
    &lt;value&gt;cdh1:8031&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
    &lt;value&gt;cdh1:8032&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
    &lt;value&gt;cdh1:8030&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
    &lt;value&gt;cdh1:8033&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
    &lt;value&gt;cdh1:8088&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>在 <code>/etc/hadoop/conf/yarn-site.xml</code> 中添加如下配置：</p>

<pre><code class="language-xml">&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.application.classpath&lt;/name&gt;
   &lt;value&gt;
    $HADOOP_CONF_DIR,
    $HADOOP_COMMON_HOME/*,
    $HADOOP_COMMON_HOME/lib/*,
    $HADOOP_HDFS_HOME/*,
    $HADOOP_HDFS_HOME/lib/*,
    $HADOOP_MAPRED_HOME/*,
    $HADOOP_MAPRED_HOME/lib/*,
    $HADOOP_YARN_HOME/*,
    $HADOOP_YARN_HOME/lib/*
    &lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;yarn.log.aggregation.enable&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p><strong>注意：</strong></p>

<ul>
  <li>
    <p><code>yarn.nodemanager.aux-services</code> 的值在 cdh4 中应该为 <code>mapreduce.shuffle</code>，并配置参数<code>yarn.nodemanager.aux-services.mapreduce.shuffle.class</code>值为 <code>org.apache.hadoop.mapred.ShuffleHandler</code> ，在cdh5中为<code>mapreduce_shuffle</code>，这时候请配置<code>yarn.nodemanager.aux-services.mapreduce_shuffle.class</code>参数</p>
  </li>
  <li>
    <p>这里配置了 <code>yarn.application.classpath</code> ，需要设置一些喜欢环境变量：</p>
  </li>
</ul>

<pre><code class="language-bash">export HADOOP_HOME=/usr/lib/hadoop
export HIVE_HOME=/usr/lib/hive
export HBASE_HOME=/usr/lib/hbase
export HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
export HADOOP_LIBEXEC_DIR=${HADOOP_HOME}/libexec
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
export YARN_CONF_DIR=${HADOOP_HOME}/etc/hadoop
</code></pre>

<p>在hadoop中默认的文件路径以及权限要求如下：</p>

<pre><code>目录									                   所有者		 权限		        默认路径
yarn.nodemanager.local-dirs			      yarn:yarn	  drwxr-xr-x    ${hadoop.tmp.dir}/nm-local-dir
yarn.nodemanager.log-dirs			        yarn:yarn	  drwxr-xr-x	  ${yarn.log.dir}/userlogs
yarn.nodemanager.remote-app-log-dir							                hdfs://cdh1:8020/var/log/hadoop-yarn/apps
</code></pre>

<p>故在 <code>/etc/hadoop/conf/yarn-site.xml</code> 文件中添加如下配置:</p>

<pre><code class="language-xml">&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;
    &lt;value&gt;/data/yarn/local&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;
    &lt;value&gt;/data/yarn/logs&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;
    &lt;value&gt;/yarn/apps&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>创建 <code>yarn.nodemanager.local-dirs</code> 和 <code>yarn.nodemanager.log-dirs</code> 参数对应的目录：</p>

<pre><code class="language-bash">$ mkdir -p /data/yarn/{local,logs}
$ chown -R yarn:yarn /data/yarn
</code></pre>

<p>在 hdfs 上创建 <code>yarn.nodemanager.remote-app-log-dir</code> 对应的目录：</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -mkdir -p /yarn/apps
$ sudo -u hdfs hadoop fs -chown yarn:mapred /yarn/apps
$ sudo -u hdfs hadoop fs -chmod 1777 /yarn/apps
</code></pre>

<p>在 <code>/etc/hadoop/conf/mapred-site.xml</code> 中配置 MapReduce History Server：</p>

<pre><code class="language-xml">&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
    &lt;value&gt;cdh1:10020&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
    &lt;value&gt;cdh1:19888&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>此外，确保 mapred、yarn 用户能够使用代理，在 <code>/etc/hadoop/conf/core-site.xml</code> 中添加如下参数：</p>

<pre><code class="language-xml">&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.mapred.groups&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.mapred.hosts&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.yarn.groups&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.yarn.hosts&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>配置 Staging 目录：</p>

<pre><code class="language-xml">&lt;property&gt;
    &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;
    &lt;value&gt;/user&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>并在 hdfs 上创建相应的目录：</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -mkdir -p /user
$ sudo -u hdfs hadoop fs -chmod 777 /user
</code></pre>

<p>可选的，你可以在 <code>/etc/hadoop/conf/mapred-site.xml</code> 设置以下两个参数：</p>

<ul>
  <li><code>mapreduce.jobhistory.intermediate-done-dir</code>，该目录权限应该为1777，默认值为 <code>${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate</code></li>
  <li><code>mapreduce.jobhistory.done-dir</code>，该目录权限应该为750，默认值为 <code>${yarn.app.mapreduce.am.staging-dir}/history/done</code></li>
</ul>

<p>然后，在 hdfs 上创建目录并设置权限：</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -mkdir -p /user/history
$ sudo -u hdfs hadoop fs -chmod -R 1777 /user/history
$ sudo -u hdfs hadoop fs -chown mapred:hadoop /user/history
</code></pre>

<p>设置 <code>HADOOP_MAPRED_HOME</code>，或者把其加入到 hadoop 的配置文件中</p>

<pre><code class="language-bash">$ export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
</code></pre>

<h2 id="hdfs-">3.4 验证 HDFS 结构：</h2>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -ls -R /
</code></pre>

<p>你应该看到如下结构：</p>

<pre><code class="language-bash">drwxrwxrwt   - hdfs hadoop          0 2014-04-19 14:21 /tmp
drwxrwxrwx   - hdfs hadoop          0 2014-04-19 14:26 /user
drwxrwxrwt   - mapred hadoop        0 2014-04-19 14:31 /user/history
drwxr-x---   - mapred hadoop        0 2014-04-19 14:38 /user/history/done
drwxrwxrwt   - mapred hadoop        0 2014-04-19 14:48 /user/history/done_intermediate
drwxr-xr-x   - hdfs   hadoop        0 2014-04-19 15:31 /yarn
drwxrwxrwt   - yarn   mapred        0 2014-04-19 15:31 /yarn/apps
</code></pre>

<h2 id="section-11">3.5 同步配置文件</h2>

<p>同步配置文件到整个集群:</p>

<pre><code class="language-bash">$ scp -r /etc/hadoop/conf root@cdh2:/etc/hadoop/
$ scp -r /etc/hadoop/conf root@cdh3:/etc/hadoop/
</code></pre>

<h2 id="section-12">3.6 启动服务</h2>

<p>在每个节点启动 YARN :</p>

<pre><code class="language-bash">$ for x in `ls /etc/init.d/|grep hadoop-yarn` ; do service $x start ; done
</code></pre>

<p>在 cdh1 节点启动 mapred-historyserver :</p>

<pre><code class="language-bash">$ /etc/init.d/hadoop-mapreduce-historyserver start
</code></pre>

<p>为每个 MapReduce 用户创建主目录，比如说 hive 用户或者当前用户：</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -mkdir /user/$USER
$ sudo -u hdfs hadoop fs -chown $USER /user/$USER
</code></pre>

<h2 id="section-13">3.7 测试</h2>

<p>通过 <a href="http://cdh1:8088/">http://cdh1:8088/</a> 可以访问 Yarn 的管理页面，通过 <a href="http://cdh1:19888/">http://cdh1:19888/</a> 可以访问 JobHistory 的管理页面，查看在线的节点：<a href="http://cdh1:8088/cluster/nodes">http://cdh1:8088/cluster/nodes</a>。</p>

<p>运行下面的测试程序，看是否报错：</p>

<pre><code class="language-bash"># Find how many jars name ending with examples you have inside location /usr/lib/
$ find /usr/lib/ -name "*hadoop*examples*.jar"

# To list all the class name inside jar
$ find /usr/lib/ -name "hadoop-examples.jar" | xargs -0 -I '{}' sh -c 'jar tf {}'

# To search for specific class name inside jar
$ find /usr/lib/ -name "hadoop-examples.jar" | xargs -0 -I '{}' sh -c 'jar tf {}' | grep -i wordcount.class

# 运行 randomwriter 例子
$ sudo -u hdfs hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar randomwriter out
</code></pre>

<h1 id="zookeeper">4. 安装 Zookeeper</h1>

<p>Zookeeper 至少需要3个节点，并且节点数要求是基数，这里在所有节点上都安装 Zookeeper。</p>

<h2 id="section-14">4.1 安装</h2>

<p>在每个节点上安装zookeeper：</p>

<pre><code class="language-bash">$ yum install zookeeper* -y
</code></pre>

<h2 id="section-15">4.2 修改配置文件</h2>

<p>设置 zookeeper 配置 <code>/etc/zookeeper/conf/zoo.cfg</code></p>

<pre><code class="language-properties">maxClientCnxns=50
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/var/lib/zookeeper
clientPort=2181
server.1=cdh1:2888:3888
server.2=cdh3:2888:3888
server.3=cdh3:2888:3888
</code></pre>

<p>##4.3  同步配置文件</p>

<p>将配置文件同步到其他节点：</p>

<pre><code class="language-bash">$ scp -r /etc/zookeeper/conf root@cdh2:/etc/zookeeper/
$ scp -r /etc/zookeeper/conf root@cdh3:/etc/zookeeper/
</code></pre>

<h2 id="section-16">4.4 初始化并启动服务</h2>

<p>在每个节点上初始化并启动 zookeeper，注意 n 的值需要和 zoo.cfg 中的编号一致。</p>

<p>在 cdh1 节点运行：</p>

<pre><code class="language-bash">$ service zookeeper-server init --myid=1
$ service zookeeper-server start
</code></pre>

<p>在 cdh2 节点运行：</p>

<pre><code class="language-bash">$ service zookeeper-server init --myid=2
$ service zookeeper-server start
</code></pre>

<p>在 cdh3 节点运行：</p>

<pre><code>$ service zookeeper-server init --myid=3
$ service zookeeper-server start
</code></pre>

<h2 id="section-17">4.5 测试</h2>

<p>通过下面命令测试是否启动成功：</p>

<pre><code class="language-bash">$ zookeeper-client -server cdh1:2181
</code></pre>

<h1 id="hbase">5. 安装 HBase</h1>

<p>HBase 依赖 ntp 服务，故需要提前安装好 ntp。</p>

<h2 id="section-18">5.1 安装前设置</h2>

<p>1）修改系统 ulimit 参数，在 <code>/etc/security/limits.conf</code> 中添加下面两行并使其生效：</p>

<pre><code>hdfs  -       nofile  32768
hbase -       nofile  32768
</code></pre>

<p>2）修改 <code>dfs.datanode.max.xcievers</code>，在 <code>hdfs-site.xml</code> 中修改该参数值，将该值调整到较大的值：</p>

<pre><code class="language-xml">&lt;property&gt;
  &lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt;
  &lt;value&gt;8192&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<h2 id="section-19">5.2 安装</h2>

<p>在每个节点上安装 master 和 regionserver，如果需要你可以安装 hbase-rest、hbase-solr-indexer、hbase-thrift</p>

<pre><code class="language-bash">$ yum install hbase hbase-master hbase-regionserver -y
</code></pre>

<h2 id="section-20">5.3 修改配置文件</h2>

<p>修改 <code>hbase-site.xml</code>文件，关键几个参数及含义如下：</p>

<ul>
  <li><code>hbase.distributed</code>：是否为分布式模式</li>
  <li><code>hbase.rootdir</code>：HBase在hdfs上的目录路径</li>
  <li><code>hbase.tmp.dir</code>：本地临时目录</li>
  <li><code>hbase.zookeeper.quorum</code>：zookeeper集群地址，逗号分隔</li>
  <li><code>hbase.hregion.max.filesize</code>：hregion文件最大大小</li>
  <li><code>hbase.hregion.memstore.flush.size</code>：memstore文件最大大小</li>
</ul>

<p>另外，在CDH5中建议<code>关掉Checksums</code>（见<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/cdh5ig_hbase_upgrade.html">Upgrading HBase</a>）以提高性能，最后的配置如下：</p>

<pre><code class="language-xml">&lt;configuration&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
      &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.rootdir&lt;/name&gt;
      &lt;value&gt;hdfs://cdh1:8020/hbase&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.tmp.dir&lt;/name&gt;
      &lt;value&gt;/data/hbase&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
      &lt;value&gt;cdh1,cdh2,cdh3&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hregion.max.filesize&lt;/name&gt;
    &lt;value&gt;536870912&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt;
    &lt;value&gt;67108864&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.lease.period&lt;/name&gt;
    &lt;value&gt;600000&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.client.retries.number&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt;
    &lt;value&gt;100&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hstore.compactionThreshold&lt;/name&gt;
    &lt;value&gt;10&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hstore.blockingStoreFiles&lt;/name&gt;
    &lt;value&gt;30&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.checksum.verify&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hstore.checksum.algorithm&lt;/name&gt;
    &lt;value&gt;NULL&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>在 hdfs 中创建 <code>/hbase</code> 目录</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -mkdir /hbase
$ sudo -u hdfs hadoop fs -chown hbase:hbase /hbase
</code></pre>

<p>设置 crontab 定时删除日志：</p>

<pre><code>$ crontab -e
* 10 * * * cd /var/log/hbase/; rm -rf `ls /var/log/hbase/|grep -P 'hbase\-hbase\-.+\.log\.[0-9]'\`&gt;&gt; /dev/null &amp;
</code></pre>

<h2 id="section-21">5.4 同步配置文件</h2>

<p>将配置文件同步到其他节点：</p>

<pre><code class="language-bash">$ scp -r /etc/hbase/conf root@cdh2:/etc/hbase/
$ scp -r /etc/hbase/conf root@cdh3:/etc/hbase/
</code></pre>

<h2 id="section-22">5.5 创建本地目录</h2>

<p>在 hbase-site.xml 配置文件中配置了 <code>hbase.tmp.dir</code> 值为 <code>/data/hbase</code>，现在需要在每个 hbase 节点创建该目录并设置权限：</p>

<pre><code class="language-bash">$ mkdir /data/hbase
$ chown -R hbase:hbase /data/hbase/
</code></pre>

<h2 id="hbase-1">5.6 启动HBase</h2>

<pre><code class="language-bash">$ for x in `ls /etc/init.d/|grep hbase` ; do service $x start ; done
</code></pre>

<h2 id="section-23">5.7 测试</h2>

<p>通过 <a href="http://cdh1:60030/">http://cdh1:60030/</a> 可以访问 RegionServer 页面，然后通过该页面可以知道哪个节点为 Master，然后再通过 60010 端口访问 Master 管理界面。</p>

<h1 id="hive">6. 安装hive</h1>

<p>在一个 NameNode 节点上安装 hive：</p>

<pre><code class="language-bash">$ yum install hive hive-metastore hive-server2 hive-jdbc hive-hbase  -y
</code></pre>

<p>在其他 DataNode 上安装：</p>

<pre><code class="language-bash">$ yum install hive hive-server2 hive-jdbc hive-hbase -y
</code></pre>

<h2 id="postgresql">安装postgresql</h2>

<p>这里使用 postgresq l数据库来存储元数据，如果你想使用 mysql 数据库，请参考下文。手动安装、配置 postgresql 数据库，请参考 <a href="/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH.html">手动安装Cloudera Hive CDH</a></p>

<p>yum 方式安装：</p>

<pre><code>$ yum install postgresql-server postgresql-jdbc -y

$ ln -s /usr/share/java/postgresql-jdbc.jar /usr/lib/hive/lib/postgresql-jdbc.jar
</code></pre>

<p>配置开启启动，并初始化数据库：</p>

<pre><code class="language-bash">$ chkconfig postgresql on
$ service postgresql initdb
</code></pre>

<p>修改配置文件postgresql.conf，修改完后内容如下：</p>

<pre><code class="language-bash">$ cat /var/lib/pgsql/data/postgresql.conf  | grep -e listen -e standard_conforming_strings
	listen_addresses = '*'
	standard_conforming_strings = off
</code></pre>

<p>修改 /var/lib/pgsql/data/pg_hba.conf，添加以下一行内容：</p>

<pre><code>	host    all         all         0.0.0.0/0                     trust
</code></pre>

<p>创建数据库和用户，设置密码为hive：</p>

<pre><code class="language-bash">su -c "cd ; /usr/bin/pg_ctl start -w -m fast -D /var/lib/pgsql/data" postgres
su -c "cd ; /usr/bin/psql --command \"create user hive with password 'hive'; \" " postgres
su -c "cd ; /usr/bin/psql --command \"drop database hive;\" " postgres
su -c "cd ; /usr/bin/psql --command \"CREATE DATABASE sentry owner=hive;\" " postgres
su -c "cd ; /usr/bin/psql --command \"GRANT ALL privileges ON DATABASE hive TO hive;\" " postgres
su -c "cd ; /usr/bin/pg_ctl restart -w -m fast -D /var/lib/pgsql/data" postgres
</code></pre>

<p>这时候的hive-site.xml文件内容如下：</p>

<pre><code class="language-xml">&lt;configuration&gt;
	    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
        &lt;value&gt;jdbc:postgresql://localhost/hive&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
        &lt;value&gt;org.postgresql.Driver&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
        &lt;value&gt;hive&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
        &lt;value&gt;hive&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;datanucleus.autoCreateSchema&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
        &lt;value&gt;cdh1:8031&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hive.auto.convert.join&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
        &lt;value&gt;/user/hive/warehouse&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.warehouse.subdir.inherit.perms&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.metastore.uris&lt;/name&gt;
        &lt;value&gt;thrift://cdh1:9083&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.metastore.client.socket.timeout&lt;/name&gt;
        &lt;value&gt;36000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.support.concurrency&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;cdh1,cdh2,cdh3&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.server2.thrift.min.worker.threads&lt;/name&gt;
        &lt;value&gt;5&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hive.server2.thrift.max.worker.threads&lt;/name&gt;
        &lt;value&gt;100&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>默认情况下，hive-server和 hive-server2 的 thrift 端口都为10000，如果要修改 hive-server2 thrift 端口，请修改 <code>hive.server2.thrift.port</code> 参数的值。</p>

<p>如果要设置运行 hive 的用户为连接的用户而不是启动用户，则添加：</p>

<pre><code class="language-xml">&lt;property&gt;
    &lt;name&gt;hive.server2.enable.impersonation&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>并在 core-site.xml 中添加：</p>

<pre><code class="language-xml">&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.hive.hosts&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.hive.groups&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<h2 id="mysql">安装mysql</h2>

<p>yum方式安装mysql以及jdbc驱动：</p>

<pre><code class="language-bash">$ yum install mysql mysql-devel mysql-server mysql-libs -y

$ yum install mysql-connector-java
$ ln -s /usr/share/java/mysql-connector-java.jar /usr/lib/hive/lib/mysql-connector-java.jar
</code></pre>

<p>创建数据库和用户，并设置密码为hive：</p>

<pre><code class="language-bash">$ mysql -e "
	CREATE DATABASE hive;
	USE hive;
	CREATE USER 'hive'@'localhost' IDENTIFIED BY 'hive';
	GRANT ALL PRIVILEGES ON metastore.* TO 'hive'@'localhost';
	GRANT ALL PRIVILEGES ON metastore.* TO 'hive'@'cdh1';
	FLUSH PRIVILEGES;
"
</code></pre>

<p>如果是第一次安装，则初始化 hive 的元数据库：</p>

<pre><code class="language-bash">$ /usr/lib/hive/bin/schematool --dbType mysql --initSchema
</code></pre>

<p>如果是更新，则执行：</p>

<pre><code class="language-bash">$ /usr/lib/hive/bin/schematool --dbType mysql --upgradeSchema
</code></pre>

<p>配置开启启动并启动数据库：</p>

<pre><code class="language-bash">$ chkconfig mysqld on
$ service mysqld start
</code></pre>

<p>修改 hive-site.xml 文件中以下内容：</p>

<pre><code class="language-xml">	&lt;property&gt;
	  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
	  &lt;value&gt;jdbc:mysql://cdh1:3306/hive?useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
	  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
	&lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
                &lt;value&gt;hive&lt;/value&gt;
            &lt;/property&gt;

            &lt;property&gt;
                &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
                &lt;value&gt;hive&lt;/value&gt;
            &lt;/property&gt;
</code></pre>

<h2 id="hive-1">配置hive</h2>

<p>修改<code>/etc/hadoop/conf/hadoop-env.sh</code>，添加环境变量 <code>HADOOP_MAPRED_HOME</code>，如果不添加，则当你使用 yarn 运行 mapreduce 时候会出现 <code>UNKOWN RPC TYPE</code> 的异常</p>

<pre><code class="language-bash">export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
</code></pre>

<p>在 hdfs 中创建 hive 数据仓库目录:</p>

<ul>
  <li>hive 的数据仓库在 hdfs 中默认为 <code>/user/hive/warehouse</code>,建议修改其访问权限为 <code>1777</code>，以便其他所有用户都可以创建、访问表，但不能删除不属于他的表。</li>
  <li>每一个查询 hive 的用户都必须有一个 hdfs 的 home 目录( <code>/user</code> 目录下，如 root 用户的为 <code>/user/root</code>)</li>
  <li>hive 所在节点的 <code>/tmp</code> 必须是 world-writable 权限的。</li>
</ul>

<p>创建目录并设置权限：</p>

<pre><code class="language-bash">$ sudo -u hdfs hadoop fs -mkdir /user/hive
$ sudo -u hdfs hadoop fs -chown hive /user/hive

$ sudo -u hdfs hadoop fs -mkdir /user/hive/warehouse
$ sudo -u hdfs hadoop fs -chmod 1777 /user/hive/warehouse
$ sudo -u hdfs hadoop fs -chown hive /user/hive/warehouse
</code></pre>

<p>启动hive-server和metastore:</p>

<pre><code class="language-bash">$ service hive-metastore start
$ service hive-server start
$ service hive-server2 start
</code></pre>

<h2 id="section-24">测试</h2>

<pre><code class="language-bash">$ hive -e 'create table t(id int);'
$ hive -e 'select * from t limit 2;'
$ hive -e 'select id from t;'
</code></pre>

<p>访问beeline:</p>

<pre><code class="language-bash">$ beeline
beeline&gt; !connect jdbc:hive2://localhost:10000 hive hive org.apache.hive.jdbc.HiveDriver
</code></pre>

<h2 id="hbase-2">与hbase集成</h2>

<p>先安装 hive-hbase:</p>

<pre><code class="language-bash">$ yum install hive-hbase -y
</code></pre>

<p>如果你是使用的 cdh4，则需要在 hive shell 里执行以下命令添加 jar：</p>

<pre><code class="language-bash">$ ADD JAR /usr/lib/hive/lib/zookeeper.jar;
$ ADD JAR /usr/lib/hive/lib/hbase.jar;
$ ADD JAR /usr/lib/hive/lib/hive-hbase-handler-&lt;hive_version&gt;.jar
# guava 包的版本以实际版本为准。
$ ADD JAR /usr/lib/hive/lib/guava-11.0.2.jar;
</code></pre>

<p>如果你是使用的 cdh5，则需要在 hive shell 里执行以下命令添加 jar：</p>

<pre><code>ADD JAR /usr/lib/hive/lib/zookeeper.jar;
ADD JAR /usr/lib/hive/lib/hive-hbase-handler.jar;
ADD JAR /usr/lib/hbase/lib/guava-12.0.1.jar;
ADD JAR /usr/lib/hbase/hbase-client.jar;
ADD JAR /usr/lib/hbase/hbase-common.jar;
ADD JAR /usr/lib/hbase/hbase-hadoop-compat.jar;
ADD JAR /usr/lib/hbase/hbase-hadoop2-compat.jar;
ADD JAR /usr/lib/hbase/hbase-protocol.jar;
ADD JAR /usr/lib/hbase/hbase-server.jar;
</code></pre>

<p>以上你也可以在 hive-site.xml 中通过 <code>hive.aux.jars.path</code> 参数来配置，或者你也可以在 hive-env.sh 中通过 <code>export HIVE_AUX_JARS_PATH=</code> 来设置。</p>

<h1 id="section-25">7. 参考文章</h1>

<ul>
  <li>[1] <a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/CDH5-Installation-Guide.html">CDH5-Installation-Guide</a></li>
  <li>[2] <a href="http://roserouge.iteye.com/blog/1558498">hadoop cdh 安装笔记</a></li>
</ul>

                    <br/>
                    <div class="well">
                        原创文章，转载请注明： 转载自<a href="http://blog.javachen.com">JavaChen Blog</a>，作者：<a href="http://blog.javachen.com/about.html">yuke</a><br/>
                        本文链接地址：<a href="/2013/04/06/install-cloudera-cdh-by-yum.html">http://blog.javachen.com/2013/04/06/install-cloudera-cdh-by-yum.html</a><br/>
                        本文基于<a target="_blank" title="Creative Commons Attribution 2.5 China Mainland License" href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。
                        如您有任何疑问或者授权方面的协商，请邮件联系我</a>。
                    </div>
                    <div class="col-md-6">
                      <p class="text-success hidden-print"><i class="fa fa-external-link"></i> <a href="/2013/04/06/install-cloudera-cdh-by-yum.html">使用yum源安装CDH Hadoop集群</a></p>
                    </div>
                    <div class="col-md-6">
                       <p class="meta hidden-print pull-right">
                        
                            <i class="fa fa-folder-open"></i>
                            
                            <a class="btn btn-default btn-sm" href="/categories.html#hadoop">hadoop</a>
                          
                        
                        
                            <i class="fa fa-tags"></i>
                            
                            <a class="btn btn-default btn-sm" href="/tags.html#hadoop">hadoop</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#hdfs">hdfs</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#yarn">yarn</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#hive">hive</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#hbase">hbase</a>
                          
                        </p>
                    </div>
               </div><!--#post-text-->
          </div><!--#post-->
      </div> <!--#content-->

      <div id="post-comment" class="hidden-print">
      
<div id="comments">
  <div class="ds-thread" data-thread-key="/2013/04/06/install-cloudera-cdh-by-yum.html" data-url="http://blog.javachen.com/2013/04/06/install-cloudera-cdh-by-yum.html" data-title="使用yum源安装CDH Hadoop集群"></div>
</div>



      </div>


          </div>
          <a href="#" class="btn back-to-top btn-dark btn-fixed-bottom hidden-print"><i class="fa fa-chevron-up"></i></a>
      </div>
      <div id="footer">
          <div class="container hidden-print">
              <p class="text-center"><i class="fa fa-copyright"></i> 2015 JavaChen Blog. Theme designed by <a href="/about.html" target="_blank" title="">yuke</a> with <a href="https://github.com/mojombo/jekyll/">Jekyll</a>, <a href="http://twitter.github.com/bootstrap/">Bootstrap</a> and <a href="http://fortawesome.github.com/Font-Awesome/">Font Awesome</a>.
  	            
            <script type="text/javascript">
                var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
                document.write(unescape("%3Cspan id='cnzz_stat_icon_1256628929'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1256628929' type='text/javascript'%3E%3C/script%3E"));</script>
            
            
    </p>
          </div>
      </div>

      <script type="text/javascript" src="/static/contrib/jquery/jquery.min.js"></script>
      <script type="text/javascript" src="/static/contrib/bootstrap/js/bootstrap.min.js"></script>
      <script type="text/javascript" src="/static/contrib/qrcode/jquery.qrcode.min.js"></script>
      <script type="text/javascript" src="/static/contrib/showup/showup.js"></script>
      <script type="text/javascript" src="/static/js/core.js"></script>
      
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"javachen"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
      

      <script type="text/javascript">
      $('#qr').qrcode({
          width: 128,
          height: 128,
          text: 'http://blog.javachen.com/2013/04/06/install-cloudera-cdh-by-yum.html'
      });
      </script>
  </body>
</html>
