<!DOCTYPE html>
<html lang="zh-cn">
        <head>
      <meta charset="utf-8"/>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
      <title>Hive中如何确定map数 - JavaChen Blog</title>
      <meta name="author" content="Junez"/>
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
      <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
      <link rel="canonical" href="http://blog.javachen.com/2013/09/04/how-to-decide-map-number.html" />

      <link rel="stylesheet" href="/static/contrib/bootstrap/css/bootstrap.min.css" media="all" />
      <link rel="stylesheet" href="/static/css/style.css" media="all" />
      <link rel="stylesheet" href="/static/css/pygments.css" media="all" />
      <link rel="stylesheet" href="/static/contrib/font-awesome/css/font-awesome.min.css" media="all" />
      <link rel="stylesheet" type="text/css" href="/static/contrib/showup/showup.css" />

      <!-- atom & rss feed -->
      <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="JavaChen Blog RSS Feed" />
      <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="JavaChen Blog ATOM Feed" />

        <!-- fav and touch icons  -->
        <!-- Update these with your own images
        <link rel="shortcut icon" href="images/favicon.ico">
        <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
        <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
        -->

      <meta name="renderer" content="webkit|ie-stand">
      <meta name="baidu-site-verification" content="3HAhaWRiyR" />
      <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
      <meta name="sogou_site_verification" content="ofwXWFdthV"/>
      <meta property="wb:webmaster" content="b6081b2b8ab84c60" />
    </head>

    <body>
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">JavaChen Blog</a>
        </div>
        <div class="navbar-collapse collapse">
            <form id="search-form" class="form-group navbar-form navbar-right" role="search">
                  <div class="form-group">
                    <input type="text" name="q" value=""  id="query" class="form-control" placeholder="搜索" required autocomplete="off" ></input>
                    <input type="submit" class="btn btn-default" value=" Go" ></input>
                  </div>
              </form>
            <ul class="nav navbar-nav">
              <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
              <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
              <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
              <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
              
              <li><a href="https://github.com/javachen" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
              
              
              
              <li><a href="https://twitter.com/junezchen" target="_blank" title="twitter"><span class="fa fa-twitter fa-2x"></span></a></li>
              
              
              
              <li><a href="http://weibo.com/chenzhijun" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
              
              <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
            </ul>
        </div>

        </div><!--/.nav-collapse -->
      </div>
</div>

      <div id="wrap">
          <div class="container">
                 <div id="content">
          <ul class="pager hidden-print">
               
                <li class="previous"><a href="/2013/08/31/my-jekyll-config.html" title="我的jekyll配置和修改"><i class="fa fa-angle-double-left"></i>&nbsp;我的jekyll配置和修改</a></li>
                
                
                <li class="next"><a href="/2013/09/08/recent-work.html" title="最近的工作">最近的工作&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
                
          </ul>

           <div id="post" class="clearfix">
              <div id="post-title" class="page-header text-center">
                  <h1> Hive中如何确定map数  </h1>
              </div>
              <p class="text-muted clearfix">
                  <span class="pull-right">2013.09.04 | <a href="#comments">Comments</a></span>
              </p>
              <div id="qr" class="qrcode visible-lg"></div>

              <div id="post-text">
                    <p>Hive 是基于 Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sq l语句转换为 MapReduce 任务进行运行。当运行一个 hql 语句的时候，map 数是如何计算出来的呢？有哪些方法可以调整 map 数呢？</p>

<p>本文测试集群版本：<code>cdh-4.3.0</code> 。</p>

<h1 id="hive--input-format">hive 默认的 input format</h1>

<p>在 <code>cdh-4.3.0</code> 的 hive 中查看 <code>hive.input.format</code> 值（为什么是<code>hive.input.format</code>？）：</p>

<pre><code class="language-bash">hive&gt; set hive.input.format;
hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
</code></pre>

<p>可以看到默认值为 CombineHiveInputFormat，如果你使用的是 <code>IDH</code> 的hive，则默认值为：</p>

<pre><code class="language-bash">hive&gt; set hive.input.format;
hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
</code></pre>

<p>CombineHiveInputFormat 类继承自 HiveInputFormat，而 HiveInputFormat 实现了 <code>org.apache.hadoop.mapred.InputFormat</code> 接口，关于 InputFormat 的分析，可以参考<a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a>.</p>

<h1 id="inputformat-">InputFormat 接口功能</h1>

<p>简单来说，InputFormat 主要用于描述输入数据的格式，提供了以下两个功能：</p>

<p>1)、数据切分，按照某个策略将输入数据且分成若干个 split，以便确定 Map Task 的个数即 Mapper 的个数，在 MapReduce 框架中，一个 split 就意味着需要一个 Map Task;</p>

<p>2)、为 Mapper 提供输入数据，即给定一个 split(使用其中的 RecordReader 对象)将之解析为一个个的 key/value 键值对。</p>

<p>该类接口定义如下：</p>

<pre><code class="language-java">public interface InputFormat&lt;K,V&gt;{
	public InputSplit[] getSplits(JobConf job,int numSplits) throws IOException; 
	public RecordReader&lt;K,V&gt; getRecordReader(InputSplit split,JobConf job,Reporter reporter) throws IOException; 
}
</code></pre>

<p>其中，<code>getSplit()</code> 方法主要用于切分数据，每一份数据由，split 只是在逻辑上对数据分片，并不会在磁盘上将数据切分成 split 物理分片，实际上数据在 HDFS 上还是以 block 为基本单位来存储数据的。InputSplit 只记录了 Mapper 要处理的数据的元数据信息，如起始位置、长度和所在的节点。</p>

<p>MapReduce 自带了一些 InputFormat 的实现类：</p>

<p><img src="http://dl2.iteye.com/upload/attachment/0085/0423/fa2e8c9f-f26a-3184-98e7-277c1b56fda1.jpg" alt="InputFormat实现类" /></p>

<p>hive 中有一些 InputFormat 的实现类，如：</p>

<pre><code class="language-java">AvroContainerInputFormat
RCFileBlockMergeInputFormat
RCFileInputFormat
FlatFileInputFormat
OneNullRowInputFormat
ReworkMapredInputFormat
SymbolicInputFormat
SymlinkTextInputFormat
HiveInputFormat
</code></pre>

<p>HiveInputFormat 的子类有：</p>

<p><img src="http://7xnrdo.com1.z0.glb.clouddn.com/2013/implement-of-hiveinputformat.png" alt="HiveInputFormat的子类" /></p>

<h1 id="hiveinputformat">HiveInputFormat</h1>

<p>以 HiveInputFormat 为例，看看其getSplit()方法逻辑：</p>

<pre><code class="language-java">for (Path dir : dirs) {
  PartitionDesc part = getPartitionDescFromPath(pathToPartitionInfo, dir);
  // create a new InputFormat instance if this is the first time to see this
  // class
  Class inputFormatClass = part.getInputFileFormatClass();
  InputFormat inputFormat = getInputFormatFromCache(inputFormatClass, job);
  Utilities.copyTableJobPropertiesToConf(part.getTableDesc(), newjob);

  // Make filter pushdown information available to getSplits.
  ArrayList&lt;String&gt; aliases =
      mrwork.getPathToAliases().get(dir.toUri().toString());
  if ((aliases != null) &amp;&amp; (aliases.size() == 1)) {
    Operator op = mrwork.getAliasToWork().get(aliases.get(0));
    if ((op != null) &amp;&amp; (op instanceof TableScanOperator)) {
      TableScanOperator tableScan = (TableScanOperator) op;
      pushFilters(newjob, tableScan);
    }
  }

  FileInputFormat.setInputPaths(newjob, dir);
  newjob.setInputFormat(inputFormat.getClass());
  InputSplit[] iss = inputFormat.getSplits(newjob, numSplits / dirs.length);
  for (InputSplit is : iss) {
    result.add(new HiveInputSplit(is, inputFormatClass.getName()));
  }
}
</code></pre>

<p>上面代码主要过程是：</p>

<blockquote>
  <p>遍历每个输入目录，然后获得 PartitionDesc 对象，从该对象调用 getInputFileFormatClass 方法得到实际的 InputFormat 类，并调用其 <code>getSplits(newjob, numSplits / dirs.length)</code> 方法。</p>
</blockquote>

<p>按照上面代码逻辑，似乎 hive 中每一个表都应该有一个 InputFormat 实现类。在 hive 中运行下面代码，可以查看建表语句：</p>

<pre><code class="language-sql">hive&gt; show create table info; 
OK
CREATE  TABLE info(
  statist_date string, 
  statistics_date string, 
  inner_code string, 
  office_no string, 
  window_no string, 
  ticket_no string, 
  id_kind string, 
  id_no string, 
  id_name string, 
  area_center_code string)
ROW FORMAT DELIMITED 
  FIELDS TERMINATED BY '\;' 
  LINES TERMINATED BY '\n' 
STORED AS INPUTFORMAT 
  'org.apache.hadoop.mapred.TextInputFormat' 
OUTPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  'hdfs://node:8020/user/hive/warehouse/info'
TBLPROPERTIES (
  'numPartitions'='0', 
  'numFiles'='1', 
  'transient_lastDdlTime'='1378245263', 
  'numRows'='0', 
  'totalSize'='301240320', 
  'rawDataSize'='0')
Time taken: 0.497 seconds
</code></pre>

<p>从上面可以看到 info 表的 INPUTFORMAT 为<code>org.apache.hadoop.mapred.TextInputFormat</code>，TextInputFormat 继承自FileInputFormat。FileInputFormat 是一个抽象类，它最重要的功能是为各种 InputFormat 提供统一的 <code>getSplits()</code>方法，该方法最核心的是文件切分算法和 Host 选择算法。</p>

<p>算法如下：</p>

<pre><code class="language-java">long length = file.getLen();
long goalSize = totalSize / (numSplits == 0 ? 1 : numSplits);
long minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.
FileInputFormat.SPLIT_MINSIZE, 1), minSplitSize);

long blockSize = file.getBlockSize();
long splitSize = computeSplitSize(goalSize, minSize, blockSize);
long bytesRemaining = length;
while (((double) bytesRemaining)/splitSize &gt; SPLIT_SLOP) {
String[] splitHosts = getSplitHosts(blkLocations, 
	length-bytesRemaining, splitSize, clusterMap);
	splits.add(makeSplit(path, length-bytesRemaining, splitSize, 
		       splitHosts));
	bytesRemaining -= splitSize;
}
</code></pre>

<hr />

<p><code>华丽的分割线</code>：以下摘抄自<a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a></p>

<p><strong>1）文件切分算法</strong></p>

<p>文件切分算法主要用于确定InputSplit的个数以及每个InputSplit对应的数据段，FileInputSplit以文件为单位切分生成InputSplit。有三个属性值来确定InputSplit的个数：</p>

<ul>
  <li><code>goalSize</code>：该值由 <code>totalSize/numSplits</code> 来确定 InputSplit 的长度，它是根据用户的期望的 InputSplit 个数计算出来的；numSplits 为用户设定的 Map Task 的个数，默认为1。</li>
  <li><code>minSize</code>：由配置参数 <code>mapred.min.split.size</code>（或者 <code>mapreduce.input.fileinputformat.split.minsize</code>）决定的 InputForma t的最小长度，默认为1。</li>
  <li><code>blockSize</code>：HDFS 中的文件存储块block的大小，默认为64MB。</li>
  <li><code>numSplits=mapred.map.tasks</code> 或者 <code>mapreduce.job.maps</code></li>
</ul>

<p>这三个参数决定一个 InputFormat 分片的最终的长度，计算方法如下：</p>

<pre><code class="language-java">splitSize = max{minSize,min{goalSize,blockSize}} 
</code></pre>

<p>计算出了分片的长度后，也就确定了 InputFormat 的数目。</p>

<p><strong>2）host 选择算法</strong></p>

<p>InputFormat 的切分方案确定后，接下来就是要确定每一个 InputSplit 的元数据信息。InputSplit 元数据通常包括四部分，<code>&lt;file,start,length,hosts&gt;</code>其意义为：</p>

<ul>
  <li>file 标识 InputSplit 分片所在的文件；</li>
  <li>InputSplit 分片在文件中的的起始位置；</li>
  <li>InputSplit 分片的长度；</li>
  <li>分片所在的 host 节点的列表。</li>
</ul>

<p>InputSplit 的 host 列表的算作策略直接影响到运行作业的本地性。</p>

<p>我们知道，由于大文件存储在 HDFS上的 block 可能会遍布整个 Hadoop 集群，而一个 InputSplit 分片的划分算法可能会导致一个 split 分片对应多个不在同一个节点上的 blocks，这就会使得在 Map Task 执行过程中会涉及到读其他节点上的属于该 Task 的 block 中的数据，从而不能实现数据本地性，而造成更多的网络传输开销。</p>

<p>一个 InputSplit 分片对应的 blocks 可能位于多个数据节点地上，但是基于任务调度的效率，通常情况下，不会把一个分片涉及的所有的节点信息都加到其host列表中，而是选择包含该分片的数据总量的最大的前几个节点，作为任务调度时判断是否具有本地性的主要凭证。</p>

<p>FileInputFormat 使用了一个启发式的 host 选择算法：首先按照 rack 机架包含的数据量对 rack 排序，然后再在 rack 内部按照每个 node 节点包含的数据量对 node 排序，最后选取前 N 个(N 为 block 的副本数)，node 的 host 作为 InputSplit 分片的 host 列表。当任务地调度 Task 作业时，只要将 Task 调度给 host 列表上的节点，就可以认为该 Task 满足了本地性。</p>

<p>从上面的信息我们可以知道，当 InputSplit 分片的大小大于 block 的大小时，Map Task 并不能完全满足数据的本地性，总有一本分的数据要通过网络从远程节点上读数据，故为了提高 Map Task 的数据本地性，减少网络传输的开销，应尽量是 InputFormat 的大小和 HDFS 的 block 块大小相同。</p>

<hr />

<h1 id="combinehiveinputformat">CombineHiveInputFormat</h1>

<p><code>getSplits(JobConf job, int numSplits)</code> 代码运行过程如下：</p>

<pre><code class="language-java">init(job);
CombineFileInputFormatShim combine = ShimLoader.getHadoopShims().getCombineFileInputFormat();
	ShimLoader.loadShims(HADOOP_SHIM_CLASSES, HadoopShims.class);
		Hadoop23Shims
			HadoopShimsSecure.getCombineFileInputFormat()
</code></pre>

<p>CombineFileInputFormatShim 继承了<code>org.apache.hadoop.mapred.lib.CombineFileInputFormat</code>，CombineFileInputFormatShim 的 <code>getSplits</code> 方法代码如下：</p>

<pre><code class="language-java">public InputSplitShim[] getSplits(JobConf job, int numSplits) throws IOException {
  long minSize = job.getLong("mapred.min.split.size", 0);

  // For backward compatibility, let the above parameter be used
  if (job.getLong("mapred.min.split.size.per.node", 0) == 0) {
    super.setMinSplitSizeNode(minSize);
  }

  if (job.getLong("mapred.min.split.size.per.rack", 0) == 0) {
    super.setMinSplitSizeRack(minSize);
  }

  if (job.getLong("mapred.max.split.size", 0) == 0) {
    super.setMaxSplitSize(minSize);
  }

  InputSplit[] splits = (InputSplit[]) super.getSplits(job, numSplits);

  InputSplitShim[] isplits = new InputSplitShim[splits.length];
  for (int pos = 0; pos &lt; splits.length; pos++) {
    isplits[pos] = new InputSplitShim((CombineFileSplit)splits[pos]);
  }

  return isplits;
}
</code></pre>

<p>从上面代码可以看出，如果为 CombineHiveInputFormat，则以下四个参数起作用：</p>

<ul>
  <li><code>mapred.min.split.size</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize</code>。</li>
  <li><code>mapred.max.split.size</code> 或者 <code>mapreduce.input.fileinputformat.split.maxsize</code>。</li>
  <li><code>mapred.min.split.size.per.rack</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize.per.rack</code>。</li>
  <li><code>mapred.min.split.size.per.node</code> 或者 <code>mapreduce.input.fileinputformat.split.minsize.per.node</code>。</li>
</ul>

<p>CombineFileInputFormatShim 的 getSplits 方法最终会调用父类的 getSplits 方法，拆分算法如下：</p>

<pre><code class="language-java">long left = locations[i].getLength();
long myOffset = locations[i].getOffset();
long myLength = 0;
do {
	if (maxSize == 0) {
		myLength = left;
	} else {
	if (left &gt; maxSize &amp;&amp; left &lt; 2 * maxSize) {
	  myLength = left / 2;
	} else {
	  myLength = Math.min(maxSize, left);
	}
	}
	OneBlockInfo oneblock = new OneBlockInfo(path, myOffset,
	  myLength, locations[i].getHosts(), locations[i]
	      .getTopologyPaths());
	left -= myLength;
	myOffset += myLength;

	blocksList.add(oneblock);
} while (left &gt; 0);
</code></pre>

<h1 id="hive--map-">hive 中如何确定 map 数</h1>

<p>总上总结如下：</p>

<p>如果 <code>hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat</code>，则这时候的参数如下：</p>

<pre><code class="language-bash">hive&gt; set mapred.min.split.size;
mapred.min.split.size=1
hive&gt; set mapred.map.tasks;
mapred.map.tasks=2
hive&gt; set dfs.blocksize;
dfs.blocksize=134217728
</code></pre>

<p>上面参数中 <code>mapred.map.tasks</code> 为2，<code>dfs.blocksize</code>（使用的是 cdh-4.3.0 版本的 hadoop，这里 block 和 size 之间没有逗号）为128M。</p>

<p>假设有一个文件为200M，则按上面 <code>HiveInputFormat</code> 的 split 算法：</p>

<p>1、文件总大小为200M，goalSize=200M /2 =100M，minSize=1 ，splitSize = max{1,min{100M,128M}} =100M</p>

<p>2、200M / 100M &gt;1.1,故第一块大小为100M</p>

<p>3、剩下文件大小为100M，小于128M，故第二块大小为100M。</p>

<p>如果 <code>hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</code>，则这时候的参数如下：</p>

<pre><code class="language-bash">hive&gt; set mapred.min.split.size;
mapred.min.split.size=1
hive&gt; set mapred.max.split.size;
mapred.max.split.size=67108864
hive&gt; set mapred.min.split.size.per.rack;
mapred.min.split.size.per.rack=1
hive&gt; set mapred.min.split.size.per.node;
mapred.min.split.size.per.node=1
hive&gt; set dfs.blocksize;
dfs.blocksize=134217728
</code></pre>

<p>上面参数中 <code>mapred.max.split.size</code> 为64M，<code>dfs.blocksize</code> 为128M。</p>

<p>假设有一个文件为200M，则按上面 <code>CombineHiveInputFormat</code> 的 split 算法：</p>

<p>1、128M &lt; 200M &lt;128M X 2，故第一个block大小为128M</p>

<p>2、剩下文件大小为200M-128M=72M，72M &lt; 128M,故第二块大小为72M</p>

<h1 id="section">总结</h1>

<p>网上有一些文章关于 hive 中如何控制 map 数的文章是否考虑的不够全面，没有具体情况具体分析。简而言之，当 InputFormat 的实现类为不同类时，拆分块算法都不一样，相关设置参数也不一样，需要具体分析。</p>

<h2 id="map-">1. map 数不是越多越好</h2>

<p>如果一个任务有很多小文件（远远小于块大小128m）,则每个小文件也会被当做一个块，用一个 map 任务来完成，而一个 map 任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。<br />
而且，同时可执行的 map 数是受限的。</p>

<h2 id="map--1">2. 如何适当的增加 map 数？</h2>

<ul>
  <li>将数据导入到 hive 前，手动将大文件拆分为小文件</li>
  <li>指定 map 数，使用 <code>insert</code> 或者 <code>create as select</code> 语句将一个表导入到另一个表，然后对另一张表做查询</li>
</ul>

<h2 id="section-1">3. 一些经验</h2>

<ul>
  <li>
    <p>合并小文件可以减少 map 数，但是会增加网络 IO。</p>
  </li>
  <li>
    <p>尽量使拆分块大小和 hdfs 的块大小接近，避免一个拆分块大小上的多个 hdfs 块位于不同数据节点，从而降低网络 IO。</p>
  </li>
  <li>
    <p>根据实际情况，控制 map 数量需要遵循两个原则：<code>使大数据量利用合适的map数</code>；<code>使单个map任务处理合适的数据量。</code></p>
  </li>
</ul>

<h1 id="section-2">参考文章</h1>

<ul>
  <li>[1] <a href="http://f.dataguru.cn/thread-149820-1-1.html">hive的查询注意事项以及优化总结</a></li>
  <li>[2] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c010178qd.html">Hadoop中map数的计算</a></li>
  <li>[3] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c0101aqvv.html">[Hive]从一个经典案例看优化mapred.map.tasks的重要性</a></li>
  <li>[4] <a href="http://superlxw1234.iteye.com/blog/1582880">hive优化之——控制hive任务中的map数和reduce数</a></li>
  <li>[5] <a href="http://www.searchtb.com/2010/12/hadoop-job-tuning.html">Hadoop Job Tuning</a></li>
  <li>[6] <a href="http://www.tuicool.com/articles/77f2Af">Hive配置项的含义详解（2）</a></li>
  <li>[7] <a href="http://blog.csdn.net/lalaguozhe/article/details/9053645">Hive小文件合并调研</a></li>
  <li>[8] <a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a></li>
</ul>


                    <br/>
                    <div class="well">
                        原创文章，转载请注明： 转载自<a href="http://blog.javachen.com">JavaChen Blog</a>，作者：<a href="http://blog.javachen.com/about.html">Junez</a><br/>
                        本文链接地址：<a href="/2013/09/04/how-to-decide-map-number.html">http://blog.javachen.com/2013/09/04/how-to-decide-map-number.html</a><br/>
                        本文基于<a target="_blank" title="Creative Commons Attribution 2.5 China Mainland License" href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。
                        如您有任何疑问或者授权方面的协商，请邮件联系我</a>。
                    </div>
                    <div class="col-md-6">
                      <p class="text-success hidden-print"><i class="fa fa-external-link"></i> <a href="/2013/09/04/how-to-decide-map-number.html">Hive中如何确定map数</a></p>
                    </div>
                    <div class="col-md-6">
                       <p class="meta hidden-print pull-right">
                        
                            <i class="fa fa-folder-open"></i>
                            
                            <a class="btn btn-default btn-sm" href="/categories.html#hive">hive</a>
                          
                        
                        
                            <i class="fa fa-tags"></i>
                            
                            <a class="btn btn-default btn-sm" href="/tags.html#hive">hive</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#mapreduce">mapreduce</a>
                          
                        </p>
                    </div>
               </div><!--#post-text-->
          </div><!--#post-->
      </div> <!--#content-->

      <div id="post-comment" class="hidden-print">
      
<div id="comments">
  <div class="ds-thread" data-thread-key="/2013/09/04/how-to-decide-map-number.html" data-url="http://blog.javachen.com/2013/09/04/how-to-decide-map-number.html" data-title="Hive中如何确定map数"></div>
</div>



      </div>


          </div>
          <a href="#" class="btn back-to-top btn-dark btn-fixed-bottom hidden-print"><i class="fa fa-chevron-up"></i></a>
      </div>
      <div id="footer">
          <div class="container hidden-print">
              <p class="text-center"><i class="fa fa-copyright"></i> 2015 JavaChen Blog. Theme designed by <a href="/about.html" target="_blank" title="">Junez</a> with <a href="https://github.com/mojombo/jekyll/">Jekyll</a>, <a href="http://twitter.github.com/bootstrap/">Bootstrap</a> and <a href="http://fortawesome.github.com/Font-Awesome/">Font Awesome</a>.
  	            
            <script type="text/javascript">
                var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
                document.write(unescape("%3Cspan id='cnzz_stat_icon_1256628929'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1256628929' type='text/javascript'%3E%3C/script%3E"));</script>
            
            
    </p>
          </div>
      </div>

      <script type="text/javascript" src="/static/contrib/jquery/jquery.min.js"></script>
      <script type="text/javascript" src="/static/contrib/bootstrap/js/bootstrap.min.js"></script>
      <script type="text/javascript" src="/static/contrib/qrcode/jquery.qrcode.min.js"></script>
      <script type="text/javascript" src="/static/contrib/showup/showup.js"></script>
      <script type="text/javascript" src="/static/js/core.js"></script>
      
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"javachen"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
      

      <script type="text/javascript">
      $('#qr').qrcode({
          width: 128,
          height: 128,
          text: 'http://blog.javachen.com/2013/09/04/how-to-decide-map-number.html'
      });
      </script>
  </body>
</html>
