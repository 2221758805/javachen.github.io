<!DOCTYPE html>
<html lang="zh-cn">
        <head>
      <meta charset="utf-8"/>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
      <title>HiveServer2中使用jdbc客户端用户运行mapreduce - JavaChen Blog</title>
      <meta name="author" content="JavaChen"/>
      <meta name="keywords" content="hive"/>
      <meta name="description" content="最近做了个web系统访问hive数据库，类似于官方自带的hwi，但是和他们的实现不一样，查询Hive语句走的不是cli而是通过jdbc连接hive-server2。为了实现mapreduce任务中资源按用户调度，需要hive查询自动绑定当前用户、将该用户传到yarn服务端并使mapreduce程序以该用户运行。本文主要是记录实现该功能过程中遇到的一些问题以及解决方法,如果你有更好的方法和建议，欢迎留言发表您的看法！">
      <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
      <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
      <link rel="canonical" href="http://blog.javachen.com/2013/10/17/run-mapreduce-with-client-user-in-hive-server2.html" />

      <link rel="stylesheet" href="/static/contrib/bootstrap/css/bootstrap.min.css" media="all" />
      <link rel="stylesheet" href="/static/css/style.css" media="all" />
      <link rel="stylesheet" href="/static/css/pygments.css" media="all" />
      <link rel="stylesheet" href="/static/contrib/font-awesome/css/font-awesome.min.css" media="all" />
      <link rel="stylesheet" type="text/css" href="/static/contrib/showup/showup.css" />

        <!-- fav and touch icons  -->
        <!-- Update these with your own images
        <link rel="shortcut icon" href="images/favicon.ico">
        <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
        <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
        -->

      <meta name="renderer" content="webkit|ie-stand"/>
      <meta name="baidu-site-verification" content="3HAhaWRiyR" />
      <meta name="360-site-verification" content="9b7a87a1d52051c96644f0a9b8b79898" />
      <meta name="sogou_site_verification" content="ofwXWFdthV"/>
      <meta property="wb:webmaster" content="b6081b2b8ab84c60" />
    </head>

    <body>
      <!--[if lte IE 9]>
<div class="alert alert-warning">
  <p>Your Internet Explorer is not supported. Please upgrade your Internet Explorer to version 9+, or use latest <a href="http://www.google.com/chrome/" target="_blank" class="alert-link">Google chrome</a>、<a href="http://www.mozilla.org/firefox/" target="_blank" class="alert-link">Mozilla Firefox</a>.</p>
  <p>If you are using IE 9 or later, make sure you <a href="http://windows.microsoft.com/en-us/internet-explorer/use-compatibility-view#ie=ie-8" target="_blank" class="alert-link">turn off "Compatibility view"</a>.</p>
</div>
<![endif]-->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/">JavaChen Blog</a>
        </div>
        <div class="navbar-collapse collapse">
            <form id="search-form" class="form-group navbar-form navbar-right" role="search">
                  <div class="form-group">
                    <input type="text" name="q" value=""  id="query" class="form-control" placeholder="搜索" required autocomplete="off" ></input>
                    <input type="submit" class="btn btn-default" value=" Go" ></input>
                  </div>
              </form>
            <ul class="nav navbar-nav">
              <li><a href="/archive.html" title="Archive"><span class='fa fa-archive fa-2x'></span></a></li>
              <li><a href="/categories.html" title="Categories"><span class='fa fa-navicon fa-2x'></span></a></li>
              <li><a href="/tags.html" title="Tags"><span class='fa fa-tags fa-2x'></span></a></li>
              <li><a href="/about.html" title="About"><span class='fa fa-user fa-2x'></span></a></li>
              
              <li><a href="https://github.com/javachen" target="_blank" title="Github"><span class='fa fa-github fa-2x'></span></a></li>
              
              
              
              
              
              <li><a href="http://weibo.com/chenzhijun" target="_blank" title="Weibo"><span class="fa fa-weibo fa-2x"></span></a></li>
              
              <li><a href="/rss.xml" target="_blank" title="RSS"><span class='fa fa-rss fa-2x'></span></a></li>
            </ul>
        </div>

        </div><!--/.nav-collapse -->
      </div>
</div>

      <div id="wrap">
          <div class="container">
                 <div id="content">
          <ul class="pager hidden-print">
               
                <li class="previous"><a href="/2013/10/17/cartesian-product-in-hive-inner-join.html" title="Hive连接产生笛卡尔集"><i class="fa fa-angle-double-left"></i>&nbsp;Hive连接产生笛卡尔集</a></li>
                
                
                <li class="next"><a href="/2013/10/28/compile-hbase-source-code-and-apply-patches.html" title="编译CDH HBase源代码并打补丁">编译CDH HBase源代码并打补丁&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
                
          </ul>

           <div id="post" class="clearfix">
              <div id="post-title" class="page-header text-center">
                  <h1> HiveServer2中使用jdbc客户端用户运行mapreduce  </h1>
              </div>
              <p class="text-muted clearfix">
                  <span class="pull-right">2013.10.17 | <a href="#comments">Comments</a></span>
              </p>
              <div id="qr" class="qrcode visible-lg"></div>

              <div id="post-text">
                    <p>最近做了个web系统访问hive数据库，类似于官方自带的hwi、安居客的<a href="https://github.com/anjuke/hwi">hwi改进版</a>和大众点评的<a href="http://blog.csdn.net/lalaguozhe/article/details/9614061">polestar</a>(<a href="https://github.com/dianping/polestar">github地址</a>)系统，但是和他们的实现不一样，查询Hive语句走的不是cli而是通过jdbc连接hive-server2。为了实现mapreduce任务中资源按用户调度，需要hive查询自动绑定当前用户、将该用户传到yarn服务端并使mapreduce程序以该用户运行。本文主要是记录实现该功能过程中遇到的一些问题以及解决方法,如果你有更好的方法和建议，欢迎留言发表您的看法！</p>

<h1 id="section">说明</h1>

<p>集群环境使用的是cdh4.3，没有开启kerberos认证。</p>

<blockquote>
  <p>写完这篇文章之后，在微博上收到<a href="http://weibo.com/shanchao1?from=profile&amp;wvr=5&amp;loc=infdomain">@单超eric</a>的<a href="http://weibo.com/1789178264/AeMItpBRk">评论</a>，发现cdh4.3中hive-server2已经实现<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Security-Guide/cdh4sg_topic_9_1.html#topic_9_1_unique_4">Impersonation</a>功能，再此对@单超eric的帮助表示感谢。</p>
</blockquote>

<p>so，你可以完全忽略本文后面的内容，直接看cloudera的HiveServer2 Impersonation是怎么做的。</p>

<h1 id="hive-server2">hive-server2的启动</h1>

<p>先从hive-server2服务的启动开始说起。</p>

<p>如果你是以服务的方式启动hive-server2进程，则启动hive-server2的用户为hive,运行mapreduce的用户也为hive，启动脚本如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/etc/init.d/hive-server2 start
</code></pre>
</div>

<p>如果你以命令行方式启动hive-server2进程，则启动hive-server2的用户为root,运行mapreduce的用户也为root，启动脚本如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>hive --service hiveserver2
</code></pre>
</div>

<p>为什么是上面的结论？这要从hive-server2的启动过程开始说明。</p>

<!-- more -->

<p>查看HiveServer2.java的代码可以看到，hive-server2启动时会依次启动<code class="highlighter-rouge">cliService</code>和<code class="highlighter-rouge">thriftCLIService</code>，查看cliService的init()方法，可以看到如下代码：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>public synchronized void init(HiveConf hiveConf) {
    this.hiveConf = hiveConf;

    sessionManager = new SessionManager();
    addService(sessionManager);
    try {
      HiveAuthFactory.loginFromKeytab(hiveConf);
      serverUserName = ShimLoader.getHadoopShims().
          getShortUserName(ShimLoader.getHadoopShims().getUGIForConf(hiveConf));
    } catch (IOException e) {
      throw new ServiceException("Unable to login to kerberos with given principal/keytab", e);
    } catch (LoginException e) {
      throw new ServiceException("Unable to login to kerberos with given principal/keytab", e);
    }
    super.init(hiveConf);
  }
</code></pre>
</div>

<p>从上面的代码可以看到在cliService初始化过程中会做登陆（从kertab中登陆）和获取用户名的操作：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ShimLoader.getHadoopShims().getUGIForConf(hiveConf)
</code></pre>
</div>

<p>上面代码最终会调用HadoopShimsSecure类的getUGIForConf方法：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>@Override
public UserGroupInformation getUGIForConf(Configuration conf) throws IOException {
  return UserGroupInformation.getCurrentUser();
}
</code></pre>
</div>

<p>UserGroupInformation.getCurrentUser()代码如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code> public synchronized
  static UserGroupInformation getCurrentUser() throws IOException {
    AccessControlContext context = AccessController.getContext();
    Subject subject = Subject.getSubject(context);
    if (subject == null || subject.getPrincipals(User.class).isEmpty()) {
      return getLoginUser();
    } else {
      return new UserGroupInformation(subject);
    }
  }
</code></pre>
</div>

<p>因为这时候服务刚启动，subject为空，故if分支会调用<code class="highlighter-rouge">getLoginUser()</code>方法，其代码如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  public synchronized 
  static UserGroupInformation getLoginUser() throws IOException {
    if (loginUser == null) {
      try {
        Subject subject = new Subject();
        LoginContext login;
        if (isSecurityEnabled()) {
          login = newLoginContext(HadoopConfiguration.USER_KERBEROS_CONFIG_NAME,
              subject, new HadoopConfiguration());
        } else {
          login = newLoginContext(HadoopConfiguration.SIMPLE_CONFIG_NAME, 
              subject, new HadoopConfiguration());
        }
        login.login();
        loginUser = new UserGroupInformation(subject);
        loginUser.setLogin(login);
        loginUser.setAuthenticationMethod(isSecurityEnabled() ?
                                          AuthenticationMethod.KERBEROS :
                                          AuthenticationMethod.SIMPLE);
        loginUser = new UserGroupInformation(login.getSubject());
        String fileLocation = System.getenv(HADOOP_TOKEN_FILE_LOCATION);
        if (fileLocation != null) {
          // Load the token storage file and put all of the tokens into the
          // user. Don't use the FileSystem API for reading since it has a lock
          // cycle (HADOOP-9212).
          Credentials cred = Credentials.readTokenStorageFile(
              new File(fileLocation), conf);
          loginUser.addCredentials(cred);
        }
        loginUser.spawnAutoRenewalThreadForUserCreds();
      } catch (LoginException le) {
        LOG.debug("failure to login", le);
        throw new IOException("failure to login", le);
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug("UGI loginUser:"+loginUser);
      }
    }
    return loginUser;
  }
</code></pre>
</div>

<p>因为是第一次调用getLoginUser(),故loginUser为空，接下来会创建LoginContext并调用其login方法，login方法最终会调用HadoopLoginModule的commit()方法。</p>

<p>下图是从hive-server2启动到执行HadoopLoginModule的commit()方法的调用图：</p>

<p><img src="http://7xnrdo.com1.z0.glb.clouddn.com/2013/hive-server2-invoke.png" alt="hive-server2启动过程" /></p>

<p>获取登陆用户的关键代码就在commit()，逻辑如下：</p>

<ul>
  <li>如果使用了kerberos，则为kerberos登陆用户。hive-server2中如何使用kerberos登陆，请查看官方文档。</li>
  <li>如果kerberos用户为空并且没有开启security，则从系统环境变量中取<code class="highlighter-rouge">HADOOP_USER_NAME</code>的值</li>
  <li>如果环境变量中没有设置<code class="highlighter-rouge">HADOOP_USER_NAME</code>，则使用系统用户，即启动hive-server2进程的用户。</li>
</ul>

<h2 id="section-1">小结</h2>

<p>hive-server2启动过程中会做登陆操作并获取到登陆用户，启动之后再次调用<code class="highlighter-rouge">UserGroupInformation.getCurrentUser()</code>取到的用户就为登陆用户了，这样会导致所有请求到hive-server2的hql最后都会以这个用户来运行mapreduce。</p>

<h1 id="hive">提交hive任务</h1>

<p>现在来看hive任务是怎么提交到yarn服务端然后运行mapreduce的。</p>

<p>为了调试简单，我在本机eclipse的hive源代码中配置<code class="highlighter-rouge">hive-site.xml、core-site.xml、mapred.xml、yarn-site.xml</code>连接测试集群,添加缺少的yarn依赖并解决hive-builtins中报错的问题，然后运行HiveServer2类的main方法。<em>注意</em>，我的电脑当前登陆用户为june，故启动hive-server2的用户为june。</p>

<p>然后，在运行jdbc测试类，运行一个简单的sql语句，大概如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>public static void test() {
	try {
		Class.forName("org.apache.hive.jdbc.HiveDriver");

		Connection conn = DriverManager.getConnection(
				"jdbc:hive2://june-mint:10000/default", "", "");

		Statement stmt = conn.createStatement();

		ResultSet rs = stmt.executeQuery("select count(1) from t");

		while (rs.next())
			System.out.println(rs.getString(1));

		rs.close();
		stmt.close();
		conn.close();
	} catch (SQLException se) {
		se.printStackTrace();
	} catch (Exception e) {
		e.printStackTrace();
	}
}
</code></pre>
</div>

<p>查看yarn监控地址<code class="highlighter-rouge">http://192.168.56.101:8088/cluster</code>，可以看到提交的mapreduce任务由june用户来运行。</p>

<p><img src="http://7xnrdo.com1.z0.glb.clouddn.com/2013/20131017-01.png" alt="yarn cluster monitor page" /></p>

<p>如何修改mapreduce任务的运行用户呢？如果了解hive提交mapreduce任务的过程的话，就应该知道hive任务会通过<code class="highlighter-rouge">org.apache.hadoop.mapred.JobClient</code>来提交。在JobClient的init方法中有如下代码：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  public void init(JobConf conf) throws IOException {
    setConf(conf);
    cluster = new Cluster(conf);
    clientUgi = UserGroupInformation.getCurrentUser();
  }
</code></pre>
</div>

<p>JobClient类中提交mapreduce任务的代码如下，见submitJobInternal方法：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Job job = clientUgi.doAs(new PrivilegedExceptionAction&lt;Job&gt; () {
	@Override
	public Job run() throws IOException, ClassNotFoundException, 
	  InterruptedException {
	  Job job = Job.getInstance(conf);
	  job.submit();
	  return job;
	}
});
</code></pre>
</div>

<p>从前面知道，hive-server2启动中会进行登陆操作并且登陆用户为june，故clientUgi对应的登陆用户也为june，故提交的mapreduce任务也通过june用户来运行。</p>

<h1 id="section-2">如何修改源代码</h1>

<p>从上面代码可以知道，修改clientUgi的获取方式就可以改变提交任务的用户。UserGroupInformation中存在如下静态方法：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  public static UserGroupInformation createRemoteUser(String user) {
    if (user == null || "".equals(user)) {
      throw new IllegalArgumentException("Null user");
    }
    Subject subject = new Subject();
    subject.getPrincipals().add(new User(user));
    UserGroupInformation result = new UserGroupInformation(subject);
    result.setAuthenticationMethod(AuthenticationMethod.SIMPLE);
    return result;
  }
</code></pre>
</div>

<p>故可以尝试使用该方法，修改JobClient的init方法如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code> public void init(JobConf conf) throws IOException {
    setConf(conf);
    cluster = new Cluster(conf);
    if(UserGroupInformation.isSecurityEnabled()){
    	clientUgi = UserGroupInformation.getCurrentUser();
    }else{
    	String user = conf.get("myExecuteName","NoName");
    	clientUgi = UserGroupInformation.createRemoteUser(user);
    }
  }
</code></pre>
</div>

<p>上面代码是在没有开启security的情况下，从环境变量（myExecuteName）获取jdbc客户端指定的用户名，然后创建一个远程的UserGroupInformation。</p>

<h2 id="section-3">为什么从环境变量中获取用户名称？</h2>

<ol>
  <li>在不考虑安全的情况下，可以由客户端任意指定用户。</li>
  <li>没有使用jdbc连接信息中的用户，是因为这样会导致每次获取jdbc连接的时候都要指定用户名，这样就没法使用已有的连接池。</li>
</ol>

<p>编译代码、替换class文件，然后重新运行HiveServer2以及jdbc测试类，查看yarn监控地址<code class="highlighter-rouge">http://192.168.56.101:8088/cluster</code>，截图如下：</p>

<p><img src="http://7xnrdo.com1.z0.glb.clouddn.com/2013/20131017-02.png" alt="yarn cluster monitor page" /></p>

<p>这时候mapreduce的运行用户变为NoName，这是因为从JobConf环境变量中找不到myExecuteName变量而使用默认值NoName的原因。</p>

<p>查看hive-server2运行日志，会发现任务运行失败，关键异常信息如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=NoName, access=WRITE, inode="/tmp/hive-june/hive_2013-10-18_21-18-12_812_378750610917949668/_tmp.-ext-10001":june:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:224)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:204)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:149)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4705)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4687)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:4661)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameToInternal(FSNamesystem.java:2696)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameToInt(FSNamesystem.java:2663)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2642)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename(NameNodeRpcServer.java:610)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename
</code></pre>
</div>

<p>出现上述异常是因为，mapreduce任务在运行过程中会生成一些临时文件，而NoName用户对临时文件没有写的权限，这些临时文件属于june用户。查看hdfs文件如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[root@edh1 lib]# hadoop fs -ls /tmp/
Found 6 items
drwx------   - june hadoop          0 2013-10-15 01:33 /tmp/hadoop-yarn
drwxr-xr-x   - june hadoop          0 2013-10-16 06:52 /tmp/hive-june
</code></pre>
</div>

<p><code class="highlighter-rouge">/tmp/hive-june</code>是hive执行过程中保存在hdfs的路径，由<code class="highlighter-rouge">hive.exec.scratchdir</code>定义，其默认值为<code class="highlighter-rouge">/tmp/hive-${user.name}</code>，而且这个文件是在<code class="highlighter-rouge">org.apache.hadoop.hive.ql.Context</code>类的构造方法中获取并在ExecDriver类的execute(DriverContext driverContext)方法中创建的。</p>

<p>类似这样的权限问题还会出现在hdfs文件<code class="highlighter-rouge">重命名、删除临时目录的时候</code>。为了避免出现这样的异常，需要修改<code class="highlighter-rouge">hive.exec.scratchdir</code>为当前用户对应的临时目录路径，并使用当前登陆用户创建、重命名、删除临时目录。</p>

<p>修改获取<code class="highlighter-rouge">hive.exec.scratchdir</code>对应的临时目录代码如下，在Context类的够找方法中修改：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    String user = conf.get(myExecuteName，“”);

    if (user != null &amp;&amp; user.trim().length() &gt; 0) {
      nonLocalScratchPath =
          new Path("/tmp/hive-" + user, executionId);
    } else {
      nonLocalScratchPath =
          new Path(HiveConf.getVar(conf, HiveConf.ConfVars.SCRATCHDIR),
              executionId);
    }
</code></pre>
</div>

<p>找到这些操作对应的代码似乎太过复杂了，修改的地方也有很多，因为这里是使用的hive-server2，故在对应的jdbc代码中修改似乎会简单很多，例如修改HiveSessionImpl类的以下三个方法：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>public OperationHandle executeStatement(String statement, Map&lt;String, String&gt; confOverlay) throws HiveSQLException{}

public void cancelOperation(final OperationHandle opHandle) throws HiveSQLException {}

public void closeOperation(final OperationHandle opHandle) throws HiveSQLException {}
</code></pre>
</div>

<p>第一个方法是运行sql语句，第二个方法是取消运行，第三个方法是关闭连接。</p>

<p>executeStatement中所做的修改如下，将<code class="highlighter-rouge">operation.run();</code>改为：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    if (operation instanceof SQLOperation) {
        try {
          String user = hiveConf.getVar(ConfVars.HIVE_SERVER2_MAPREDUCE_USERNAME);
          ugi = UserGroupInformation.createRemoteUser(user);
          ugi.doAs(new PrivilegedExceptionAction&lt;CommandProcessorResponse&gt;() {
            @Override
            public CommandProcessorResponse run() throws HiveSQLException {
              operation.run();
              return null;
            }
          });
        } catch (IOException e) {
          e.printStackTrace();
        } catch (InterruptedException e) {
          e.printStackTrace();
        }
      } else {
        operation.run();
      }
</code></pre>
</div>

<p>这里添加了判断，当operation操作时，才执行下面代码，这是为了保证从hive环境变量中获取myExecuteName的值不为空时才创建UserGroupInformation。</p>

<p>myExecuteName是新定义的hive变量，主要是用于jdbc客户端通过set语句设置myExecuteName的值为当前登陆用户名称，然后在执行sql语句。代码如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Statement stmt = conn.createStatement();

stmt.execute("set myExecuteName=aaaa");
ResultSet rs = stmt.executeQuery("select count(1) from t");

while (rs.next())
	System.out.println(rs.getString(1));
</code></pre>
</div>

<h2 id="section-4">小结</h2>

<p>上面修改的类包括：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>org.apache.hadoop.mapred.JobClient //从环境变量获取从jdbc客户端传过来的用户，即myExecuteName的值，然后以该值运行mapreduce用户
org.apache.hadoop.hive.ql.Context  //修改hive.exec.scratchdir的地址为从jdbc客户端传过来的用户对应的临时目录
org.apache.hive.service.cli.session.HiveSessionImpl //修改运行sql、取消操作、关闭连接对应的方法
</code></pre>
</div>

<h1 id="section-5">测试</h1>
<p>是用javachen用户测试,hdfs上的临时目录如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[root@edh1 lib]# hadoop fs -ls /tmp/
Found 7 items
drwx------   - june         hadoop          0 2013-10-15 01:33 /tmp/hadoop-yarn
drwxr-xr-x   - javachen.com hadoop          0 2013-10-16 07:30 /tmp/hive-javachen.com
drwxr-xr-x   - june         hadoop          0 2013-10-16 06:52 /tmp/hive-june
drwxr-xr-x   - root         hadoop          0 2013-10-15 14:13 /tmp/hive-root
drwxrwxrwt   - yarn         mapred          0 2013-10-16 07:30 /tmp/logs
</code></pre>
</div>

<p>监控页面截图：</p>

<p><img src="http://7xnrdo.com1.z0.glb.clouddn.com/2013/20131017-03.png" alt="yarn cluster monitor page" /></p>

<p>除了简单测试之外，还需要测试修改后的代码是否影响源代码的运行以及hive cli的运行。</p>

<h1 id="section-6">参考文章</h1>

<ol>
  <li><a href="https://cwiki.apache.org/confluence/display/Hive/Setting+up+HiveServer2">HiveServer2 Impersonation</a></li>
  <li><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.3.0/CDH4-Security-Guide/cdh4sg_topic_9_1.html">CDH4 HiveServer2 Security Configuration</a></li>
</ol>

<h1 id="enjoy-it-">Enjoy it ！</h1>


                    <br/>
                    <div class="well">
                        原创文章，转载请注明： 转载自<a href="http://blog.javachen.com">JavaChen Blog</a>，作者：<a href="http://blog.javachen.com/about.html">JavaChen</a><br/>
                        本文链接地址：<a href="/2013/10/17/run-mapreduce-with-client-user-in-hive-server2.html">http://blog.javachen.com/2013/10/17/run-mapreduce-with-client-user-in-hive-server2.html</a><br/>
                        本文基于<a target="_blank" title="Creative Commons Attribution 2.5 China Mainland License" href="http://creativecommons.org/licenses/by/2.5/cn/">署名2.5中国大陆许可协议</a>发布，欢迎转载、演绎或用于商业目的，但是必须保留本文署名和文章链接。
                        如您有任何疑问或者授权方面的协商，请邮件联系我</a>。
                    </div>
                    <div class="col-md-6">
                      <p class="text-success hidden-print"><i class="fa fa-external-link"></i> <a href="/2013/10/17/run-mapreduce-with-client-user-in-hive-server2.html">HiveServer2中使用jdbc客户端用户运行mapreduce</a></p>
                    </div>
                    <div class="col-md-6">
                       <p class="meta hidden-print pull-right">
                        
                            <i class="fa fa-folder-open"></i>
                            
                            <a class="btn btn-default btn-sm" href="/categories.html#hive">hive</a>
                          
                        
                        
                            <i class="fa fa-tags"></i>
                            
                            <a class="btn btn-default btn-sm" href="/tags.html#hive">hive</a>
                          
                            <a class="btn btn-default btn-sm" href="/tags.html#hiveserver2">hiveserver2</a>
                          
                        </p>
                    </div>
               </div><!--#post-text-->
          </div><!--#post-->
      </div> <!--#content-->

      <div id="post-comment" class="hidden-print">
      
<div id="comments">
  <div class="ds-thread" data-thread-key="/2013/10/17/run-mapreduce-with-client-user-in-hive-server2.html" data-url="http://blog.javachen.com/2013/10/17/run-mapreduce-with-client-user-in-hive-server2.html" data-title="HiveServer2中使用jdbc客户端用户运行mapreduce"></div>
</div>



      </div>


          </div>
          <a href="#" class="btn back-to-top btn-dark btn-fixed-bottom hidden-print"><i class="fa fa-chevron-up"></i></a>
      </div>
      <div id="footer">
          <div class="container hidden-print">
              <p class="text-center"><i class="fa fa-copyright"></i> 2016 JavaChen Blog. Theme designed by <a href="/about.html" target="_blank" title="Rumblings by a coder on Java、Web、BigData、BI、Python and so on">JavaChen</a> with <a href="https://github.com/mojombo/jekyll/">Jekyll</a>, <a href="http://twitter.github.com/bootstrap/">Bootstrap</a> and <a href="http://fortawesome.github.com/Font-Awesome/">Font Awesome</a>.
  	            

            
            <script>
              var _hmt = _hmt || [];
              (function() {
                var hm = document.createElement("script");
                hm.src = "//hm.baidu.com/hm.js?50bc6f5d9b045b5895ff44f8bbdbc611";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
              })();
            </script>
            
    </p>
          </div>
      </div>

      <script type="text/javascript" src="/static/contrib/jquery/jquery.min.js"></script>
      <script type="text/javascript" src="/static/contrib/bootstrap/js/bootstrap.min.js"></script>
      <script type="text/javascript" src="/static/contrib/qrcode/jquery.qrcode.min.js"></script>
      <script type="text/javascript" src="/static/contrib/showup/showup.js"></script>
      <script type="text/javascript" src="/static/js/core.js"></script>
      
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"javachen"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] ||
        document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
      </script>
      

      <script type="text/javascript">
      $('#qr').qrcode({
          width: 128,
          height: 128,
          text: 'http://blog.javachen.com/2013/10/17/run-mapreduce-with-client-user-in-hive-server2.html'
      });
      </script>
  </body>
</html>
